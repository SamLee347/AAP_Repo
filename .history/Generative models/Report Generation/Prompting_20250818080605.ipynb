{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeadDkMiISin"
   },
   "source": [
    "# Gemini API: Prompting Quickstart\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpOYALec6N8Z"
   },
   "source": [
    "This notebook contains examples of how to write and run your first prompts with the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0c13de5f68f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-genai>=1.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4YDYyfRYN7L"
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_count": null,
   "metadata": {
    "id": "p8K1RpmMfh20"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwtL8wmX4rqP"
   },
   "source": [
    "## Select your model\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ll79uwEK4uPJ"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTNQymX8YN9c"
   },
   "source": [
    "## Run your first prompt\n",
    "\n",
    "Use the `generate_content` method to generate responses to your prompts. You can pass text directly to generate_content, and use the `.text` property to get the text content of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSuyaGmcf6sr"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Give me python code to sort a list\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:22:13,641 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-14 13:22:13,644 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-14 13:22:13,645 INFO sqlalchemy.engine.Engine [cached since 994.3s ago] {}\n",
      "2025-08-14 13:22:13,647 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-14 13:22:13,647 INFO sqlalchemy.engine.Engine [cached since 994.3s ago] {}\n",
      "2025-08-14 13:22:13,648 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Database.db import SessionLocal\n",
    "from Database_Table import Inventory, Order\n",
    "\n",
    "def getDbContent():\n",
    "    session = SessionLocal()\n",
    "    inventory_records = session.query(Inventory).all()\n",
    "    order_records = session.query(Order).all()\n",
    "    session.close()\n",
    "    return inventory_records, order_records\n",
    "\n",
    "inventory, order = getDbContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbtoList(records):\n",
    "    output_list = []\n",
    "    for r in records:\n",
    "        if isinstance(r, Inventory):\n",
    "            data = {\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"Date\": r.Date, \n",
    "                \"Quantity\": r.ItemQuantity, \n",
    "                \"Category\": r.ItemCategory, \n",
    "                \"UnitsSold\": r.UnitsSold, \n",
    "                \"Weight\": r.Weight, \n",
    "                \"Size\": r.Size, \n",
    "                \"Priority\": r.Priority, \n",
    "                \"Dispose\": r.Dispose\n",
    "            }\n",
    "        elif isinstance(r, Order):\n",
    "            data = {\n",
    "                \"OrderId\": r.OrderId,\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"OrderQuantity\": r.OrderQuantity, \n",
    "                \"Sales\": r.Sales, \n",
    "                \"Price\": r.Price, \n",
    "                \"Discount\": r.Discount,\n",
    "                \"Profit\": r.Profit, \n",
    "                \"DateOrdered\": r.DateOrdered,\n",
    "                \"DateReceived\": r.DateReceived,\n",
    "                \"CustomerSegment\": r.CustomerSegment\n",
    "            }\n",
    "        else:\n",
    "            continue\n",
    "        output_list.append(data)\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "inventoryData = dbtoList(inventory)\n",
    "orderData = dbtoList(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "class Supervised_Models:\n",
    "    # Location Prediction Model\n",
    "    def predict_location(input_data):\n",
    "        with open('../../Supervised models/Samuel/storage_prediction_model.pkl', 'rb') as file:\n",
    "            storage_prediction_model = pickle.load(file)\n",
    "            \n",
    "        categorical_features = {\n",
    "            'Priority': ['High','Low','Medium'],\n",
    "            'Product_Type': ['Clothing','Electronics','Home Goods','Sports'],\n",
    "            'Size': ['Large','Medium','Small']\n",
    "        }\n",
    "        numerical_features = ['Order_Quantity', 'Weight']\n",
    "        one_hot_columns = []\n",
    "        \n",
    "        for feature, values in categorical_features.items():\n",
    "            for value in values:\n",
    "                one_hot_columns.append(f\"{feature}_{value}\")\n",
    "            \n",
    "        # Combine with numerical features to get all feature names\n",
    "        all_feature_names = one_hot_columns + numerical_features\n",
    "\n",
    "        features_dict = {col: 0 for col in all_feature_names}\n",
    "    \n",
    "        # Set one-hot encoded features\n",
    "        for feature, values in categorical_features.items():\n",
    "            if feature in input_data:\n",
    "                selected_value = input_data[feature]\n",
    "                one_hot_col = f\"{feature}_{selected_value}\"\n",
    "                if one_hot_col in features_dict:\n",
    "                    features_dict[one_hot_col] = 1\n",
    "    \n",
    "        # Set numerical features\n",
    "        for feature in numerical_features:\n",
    "            if feature in input_data:\n",
    "                features_dict[feature] = float(input_data[feature])\n",
    "        \n",
    "        # Convert to array in the correct order\n",
    "        features_array = np.array([features_dict[col] for col in all_feature_names]).reshape(1, -1)\n",
    "\n",
    "        prediction = storage_prediction_model.predict(features_array)\n",
    "        return prediction\n",
    "\n",
    "    def demand_forecast_preprocessor(order_data, inventory_data):\n",
    "        # Create Dataframe\n",
    "        input_df = pd.DataFrame(order_data)\n",
    "        inventory = pd.DataFrame(inventory_data)\n",
    "\n",
    "        \n",
    "        return input_df, inventory\n",
    "\n",
    "    # Demand forecast model\n",
    "    def predict_demand_forecast(input_data):\n",
    "        demand_forecast_model = joblib.load('../../Supervised models/ShernFai/model/salesforecast_model.pkl')\n",
    "        with open('../../Supervised models/ShernFai/model/salesforecast_preprocessor.pkl', 'rb') as f:\n",
    "            preprocessor_data = pickle.load(f)\n",
    "\n",
    "        categories = {\n",
    "            \"Clothing\" : [\n",
    "                \"Cleats\",\n",
    "                \"Men’s Footwear\",\n",
    "                \"Women’s Apparel\"\n",
    "            ],\n",
    "            \"Technology\": [\n",
    "                \"Electronics\",\n",
    "                \"Video Games\",\n",
    "                \"Cameras\",\n",
    "                \"Computers\",\n",
    "            ],\n",
    "            \"Sports and Fitness\": [\n",
    "                \"Cardio Equipment\",\n",
    "                \"Indoor/Outdoor Games\",\n",
    "                \"Water Sports\",\n",
    "                \"Shop By Sport\",\n",
    "                \"Camping & Hiking\",\n",
    "                \"Fishing\"\n",
    "            ],\n",
    "            \"Other\": [\n",
    "                \"Garden\",\n",
    "                \"Pet Supplies\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        cat_keys = list(categories.keys())\n",
    "        print(cat_keys)\n",
    "\n",
    "        # Extract preprocessor components\n",
    "        le_category = preprocessor_data['label_encoder_category']\n",
    "        reference_date = preprocessor_data['reference_date']\n",
    "        unique_categories = preprocessor_data['unique_categories']\n",
    "        feature_columns = preprocessor_data['feature_columns']\n",
    "\n",
    "        print(unique_categories)\n",
    "\n",
    "        # Get data\n",
    "        category_name = input_data['category']\n",
    "        future_month = input_data['month']\n",
    "        product_category_id = int(input_data['product_category_id'])\n",
    "        avg_price = float(input_data['avg_price'])\n",
    "        customer_segment = input_data['customer_segment']\n",
    "        discount_rate = float(input_data['discount_rate'])\n",
    "        \n",
    "        # Parse the future date\n",
    "        future_date = pd.to_datetime(future_month)\n",
    "        \n",
    "        # Calculate time features for the future date\n",
    "        months_since_start = ((future_date - reference_date).days / 30.44)\n",
    "        \n",
    "        # Create test data with numerical time features\n",
    "        test_data = {\n",
    "            'Category Name': category_name,\n",
    "            'Product Category Id': product_category_id,\n",
    "            'Average Product Price': avg_price,\n",
    "            'Customer Segment': customer_segment,\n",
    "            'Order Item Discount Rate': discount_rate,\n",
    "            # Time features (numerical - can handle ANY future date!)\n",
    "            'Year': future_date.year,\n",
    "            'Month': future_date.month,\n",
    "            'Quarter': future_date.quarter,\n",
    "            'Months_Since_Start': int(months_since_start),\n",
    "            'Month_Sin': np.sin(2 * np.pi * future_date.month / 12),\n",
    "            'Month_Cos': np.cos(2 * np.pi * future_date.month / 12),\n",
    "            'Year_Trend': future_date.year - reference_date.year\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        test_df = pd.DataFrame([test_data])\n",
    "        \n",
    "        # Handle unknown category\n",
    "        if category_name not in cat_keys:\n",
    "            print(f\"Unknown category '{category_name}' - using default: {cat_keys[0]}\")\n",
    "            test_df['Category Name'] = cat_keys[0]\n",
    "            category_name = cat_keys[0]\n",
    "        \n",
    "        # One-hot encode customer segment\n",
    "        test_df = pd.get_dummies(test_df, columns=['Customer Segment'], drop_first=True)\n",
    "        \n",
    "        # Ensure same columns as training (crucial!)\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "        print(test_df['Category Name'])\n",
    "        \n",
    "        # Make prediction\n",
    "        total = 0\n",
    "        num = len(categories[category_name])\n",
    "        for subclass in categories[category_name]:\n",
    "            test_df['Category Name'] = subclass\n",
    "            test_df['Category Name'] = le_category.transform(test_df['Category Name'])\n",
    "            total += demand_forecast_model.predict(test_df)\n",
    "        \n",
    "        avg_demand = total / num\n",
    "        \n",
    "        return avg_demand, category_name\n",
    "        \n",
    "s = Supervised_Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderMonth</th>\n",
       "      <th>Category</th>\n",
       "      <th>CustomerSegment</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>AverageDiscount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07</td>\n",
       "      <td>Other</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OrderMonth    Category CustomerSegment  AveragePrice  AverageDiscount\n",
       "0    2025-06  Technology       Corporate         100.0             10.0\n",
       "1    2025-07       Other        Consumer         100.0              5.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df, inventory_df = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "inventory_df\n",
    "\n",
    "# Ensure dates are in datetime format\n",
    "orders_df['DateOrdered'] = pd.to_datetime(orders_df['DateOrdered'])\n",
    "\n",
    "# Extract Month (period or string, depending on preference)\n",
    "orders_df['OrderMonth'] = orders_df['DateOrdered'].dt.to_period('M')\n",
    "\n",
    "# Merge with Category lookup table\n",
    "merged_df = orders_df.merge(inventory_df, on='ItemId', how='left')\n",
    "\n",
    "# Group and aggregate\n",
    "result_df = (\n",
    "    merged_df\n",
    "    .groupby(['OrderMonth', 'Category', 'CustomerSegment'], as_index=False)\n",
    "    .agg(\n",
    "        AveragePrice=('Price', 'mean'),\n",
    "        AverageDiscount=('Discount', 'mean')\n",
    "    )\n",
    ")\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A-5']\n",
      "['Clothing', 'Technology', 'Sports and Fitness', 'Other']\n",
      "['Accessories', 'As Seen on  TV!', 'Baby ', 'Baseball & Softball', 'Basketball', 'Books ', 'Boxing & MMA', 'CDs ', 'Cameras ', 'Camping & Hiking', 'Cardio Equipment', \"Children's Clothing\", 'Cleats', 'Computers', 'Consumer Electronics', 'Crafts', 'DVDs', 'Electronics', 'Fishing', 'Fitness Accessories', 'Garden', \"Girls' Apparel\", 'Golf Apparel', 'Golf Bags & Carts', 'Golf Balls', 'Golf Gloves', 'Golf Shoes', 'Health and Beauty', 'Hockey', 'Hunting & Shooting', 'Indoor/Outdoor Games', \"Kids' Golf Clubs\", 'Lacrosse', \"Men's Clothing\", \"Men's Footwear\", \"Men's Golf Clubs\", 'Music', 'Pet Supplies', 'Shop By Sport', 'Soccer', 'Sporting Goods', 'Strength Training', 'Tennis & Racquet', 'Toys', 'Trade-In', 'Video Games', 'Water Sports', \"Women's Apparel\", \"Women's Clothing\", \"Women's Golf Clubs\"]\n",
      "0    Clothing\n",
      "Name: Category Name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SamLe\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Men’s Footwear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\utils\\_encode.py:235\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    173\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device\u001b[38;5;241m=\u001b[39mdevice(values))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    173\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device\u001b[38;5;241m=\u001b[39mdevice(values))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\utils\\_encode.py:167\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Men’s Footwear'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(s\u001b[38;5;241m.\u001b[39mpredict_location({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPriority\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct_Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSports\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m9.78\u001b[39m\n\u001b[0;32m      8\u001b[0m }))\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_demand_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClothing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduct_category_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcustomer_segment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConsumer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiscount_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.12\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[45], line 151\u001b[0m, in \u001b[0;36mSupervised_Models.predict_demand_forecast\u001b[1;34m(input_data)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subclass \u001b[38;5;129;01min\u001b[39;00m categories[category_name]:\n\u001b[0;32m    150\u001b[0m     test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m subclass\n\u001b[1;32m--> 151\u001b[0m     test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mle_category\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m demand_forecast_model\u001b[38;5;241m.\u001b[39mpredict(test_df)\n\u001b[0;32m    154\u001b[0m avg_demand \u001b[38;5;241m=\u001b[39m total \u001b[38;5;241m/\u001b[39m num\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([])\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\utils\\_encode.py:237\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Men’s Footwear'"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print(s.predict_location({\n",
    "    \"Priority\": \"High\",\n",
    "    \"Product_Type\": \"Sports\",\n",
    "    \"Size\": \"Small\",\n",
    "    \"Order_Quantity\": 9,\n",
    "    \"Weight\": 9.78\n",
    "}))\n",
    "\n",
    "print(s.predict_demand_forecast({\n",
    "    'category': \"Clothing\",\n",
    "    'month': 5,\n",
    "    'product_category_id': 2,\n",
    "    'avg_price': 10.0,\n",
    "    'customer_segment': \"Consumer\",\n",
    "    'discount_rate': 0.12\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Products Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Overview: This section summarizes the overall performance of products\n",
    "product_overview = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate an overview of products based on the following:\n",
    "\n",
    "1. **Top Products**: Identify the top-selling products by sales volume and revenue over the past month.\n",
    "2. **Product Performance**: Analyze the performance of each product category in terms of sales, demand, and revenue.\n",
    "3. **Sales by Product**: Present a summary of sales for each product, including revenue, volume sold, and average price.\n",
    "\n",
    "Data:\n",
    "- Sales Data: {sales_data}\n",
    "- Product Categories: {product_categories_data}\n",
    "- Product Sales Volume: {sales_volume_data}\n",
    "- Product Revenue: {product_revenue_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_overview.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Distribution: This section analyzes the distribution of sales across categories\n",
    "category_distribution = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate insights on the distribution of sales across categories based on the following:\n",
    "\n",
    "1. **Category-wise Sales Volume**: Summarize the total sales volume across all product categories.\n",
    "2. **Category-wise Revenue**: Display the total revenue generated from each product category over the past month.\n",
    "3. **Category-wise Performance**: Provide insights on which product categories are performing the best in terms of sales, revenue, and customer demand.\n",
    "\n",
    "Data:\n",
    "- Sales Volume by Category: {sales_volume_by_category_data}\n",
    "- Revenue by Category: {revenue_by_category_data}\n",
    "- Product Category Performance: {category_performance_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(category_distribution.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Product Usage Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Usage Forecast: This section forecasts the future usage of products based on historical sales\n",
    "product_usage_forecast = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate a product usage forecast for the upcoming period based on historical data and trends:\n",
    "\n",
    "1. **Sales Forecast by Product**: Predict the sales volume for each product in the next quarter/year.\n",
    "2. **Demand Forecast**: Provide a demand forecast for products based on historical sales, usage probabilities, and seasonal patterns.\n",
    "3. **Future Stock Levels**: Estimate the required stock levels for each product to meet forecasted demand.\n",
    "\n",
    "Data:\n",
    "- Historical Sales Data: {historical_sales_data}\n",
    "- Product Usage Data: {usage_probabilities}\n",
    "- Seasonal Patterns: {seasonal_sales_patterns_data}\n",
    "- Current Stock Levels: {current_inventory_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_usage_forecast.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = orderData\n",
    "sales_predictions = []\n",
    "for item in orderData:\n",
    "    sales_predictions.append(s.predict_demand_forecast(item))\n",
    "product_categories = []\n",
    "current_inventory = \"\"\n",
    "usage_probabilities = \"\"\n",
    "\n",
    "sales_insights = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate a sales insights report that describes information for the following areas:\n",
    "\n",
    "1. Sales Trends: Summarize sales over the past month, quarter, and year. Provide insights on which product categories are seeing the highest demand.\n",
    "2. Product Performance: Analyze the best-selling products by quantity. Highlight the top 3 performing products.\n",
    "3. Product Demand Forecast: Based on the historical sales and usage probability, forecast the demand for the next period.\n",
    "4. Restocking or Discontinuation: Recommend which products should be restocked and which should be discontinued, based on sales trends and inventory levels.\n",
    "\n",
    "Data:\n",
    "- Historical sales data: {sales_data}\n",
    "- Sales volume predictions: {sales_predictions}\n",
    "- Product categories: {product_categories}\n",
    "- Current inventory levels: {current_inventory}\n",
    "- Usage probabilities: {usage_probabilities}'''\n",
    ")\n",
    "\n",
    "display(Markdown(sales_insights.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Supervised_Models.predict_location({\n",
    "    \"Priority\": \"High\",\n",
    "    \"Product_Type\": \"Sports\",\n",
    "    \"Size\": \"Small\",\n",
    "    \"Order_Quantity\": 9,\n",
    "    \"Weight\": 9.78\n",
    "}))\n",
    "\n",
    "print(Supervised_Models.predict_demand_forecast({\n",
    "    \"order_year\": 2025,\n",
    "    \"order_month\": 3,\n",
    "    \"product_name\": \"Nike Men's CJ Elite 2 TD Football Cleat\",\n",
    "    \"order_country\": \"Estados Unidos\",\n",
    "    \"customer_segment\": \"Consumer\"\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_optimizations = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "'''Provide detailed storage optimization recommendations based on:\n",
    "\n",
    "1. Current storage utilization metrics\n",
    "2. Model-predicted optimal locations vs current locations\n",
    "3. List of items flagged for relocation, including:\n",
    "   - Current location\n",
    "   - Recommended location\n",
    "   - Reason for recommendation\n",
    "4. Estimated space savings from optimizations\n",
    "\n",
    "Data:\n",
    "{current_storage_data}\n",
    "{location_predictions}\n",
    "{anomaly_flags}'''\n",
    ")\n",
    "\n",
    "display(Markdown(storage_optimizations.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_detected = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "'''Generate an anomalies section that:\n",
    "\n",
    "1. Lists all detected anomalies categorized by:\n",
    "   - Misplaced items\n",
    "   - Severity\n",
    "   - Data inconsistencies\n",
    "2. For each anomaly, provide:\n",
    "   - Item details\n",
    "   - Nature of anomaly\n",
    "   - Recommended corrective action\n",
    "   - Priority level (high/medium/low)\n",
    "3. Summary of potential impact if not addressed.\n",
    "\n",
    "Data:\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(anomalies_detected.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65476e75ece0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56f68c900144"
   },
   "source": [
    "Every prompt you send to the model includes parameters that control how the model generates responses. Use a `types.GenerateContentConfig` to set these, or omit it to use the defaults.\n",
    "\n",
    "Temperature controls the degree of randomness in token selection. Use higher values for more creative responses, and lower values for more deterministic responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3c68071ed8b"
   },
   "source": [
    "Note: Although you can set the `candidate_count` in the generation_config, 2.0 and later models will only return a single candidate at the this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c97c16e6a961"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some cat facts for you:\n",
       "\n",
       "1.  Domestic cats spend about **70% of their day sleeping** and 15% grooming.\n",
       "2.  The average lifespan of an outdoor cat is significantly shorter (2-5 years) compared to an **indoor cat (10-15+ years)**.\n",
       "3.  Cats use their **whiskers** to \"feel\" the world around them, gauge openings, and detect changes in air currents. They are highly sensitive tactile organs.\n",
       "4.  A group of cats is called a **clowder**, a group of kittens is called a kindle.\n",
       "5.  Cats have a unique scent gland on their paws, which is why they **knead** — it's a way of marking territory and showing contentment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='Give me a numbered list of cat facts.',\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=2000,\n",
    "        temperature=1.9,\n",
    "        stop_sequences=['\\n6'] # Limit to 5 facts.\n",
    "    )\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvkDhXtHgol7"
   },
   "source": [
    "## Learn more\n",
    "\n",
    "There's lots more to learn!\n",
    "\n",
    "* For more fun prompts, check out [Market a Jetpack](https://github.com/google-gemini/cookbook/blob/main/examples/Market_a_Jet_Backpack.ipynb).\n",
    "* Check out the [safety quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb) next to learn about the Gemini API's configurable safety settings, and what to do if your prompt is blocked.\n",
    "* For lots more details on using the Python SDK, check out the [get started notebook](./Get_started.ipynb) or the [documentation's quickstart](https://ai.google.dev/tutorials/python_quickstart)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompting.ipynb",
   "toc_visible": true
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "aap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
