{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeadDkMiISin",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# AI Applications Project: Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0c13de5f68f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Importing the generative ai\n",
    "%pip install -U -q \"google-genai>=1.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4YDYyfRYN7L"
   },
   "source": [
    "### Setting up API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p8K1RpmMfh20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Google API key: AIzaSyAWSpYEUyThH2TGJwll1k-JYIQAeo1GjOE\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "GOOGLE_API_KEY = input(\"Enter your Google API key:\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ll79uwEK4uPJ"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 18:42:14,654 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2025-08-18 18:42:14,654 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 18:42:14,655 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2025-08-18 18:42:14,656 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 18:42:14,656 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2025-08-18 18:42:14,657 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 18:42:14,657 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-18 18:42:14,659 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-18 18:42:14,660 INFO sqlalchemy.engine.Engine [generated in 0.00045s] {}\n",
      "2025-08-18 18:42:14,661 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-18 18:42:14,662 INFO sqlalchemy.engine.Engine [generated in 0.00038s] {}\n",
      "2025-08-18 18:42:14,662 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Database.db import SessionLocal\n",
    "from Database_Table import Inventory, Order\n",
    "\n",
    "def getDbContent():\n",
    "    session = SessionLocal()\n",
    "    inventory_records = session.query(Inventory).all()\n",
    "    order_records = session.query(Order).all()\n",
    "    session.close()\n",
    "    return inventory_records, order_records\n",
    "\n",
    "inventory, order = getDbContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbtoList(records):\n",
    "    output_list = []\n",
    "    for r in records:\n",
    "        if isinstance(r, Inventory):\n",
    "            data = {\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"ItemName\": r.ItemName,\n",
    "                \"Category\": r.ItemCategory,\n",
    "                \"Quantity\": r.ItemQuantity, \n",
    "                \"UnitsSold\": r.UnitsSold,\n",
    "                \"Weight\": r.Weight, \n",
    "                \"Size\": r.Size,\n",
    "                \"Priority\": r.Priority, \n",
    "                \"Location\": r.Location,\n",
    "                \"Date\": r.Date, \n",
    "                \"Dispose\": r.Dispose                \n",
    "            }\n",
    "        elif isinstance(r, Order):\n",
    "            data = {\n",
    "                \"OrderId\": r.OrderId,\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"OrderQuantity\": r.OrderQuantity, \n",
    "                \"Sales\": r.Sales, \n",
    "                \"Price\": r.Price, \n",
    "                \"Discount\": r.Discount,\n",
    "                \"Profit\": r.Profit, \n",
    "                \"DateOrdered\": r.DateOrdered,\n",
    "                \"DateReceived\": r.DateReceived,\n",
    "                \"CustomerSegment\": r.CustomerSegment\n",
    "            }\n",
    "        else:\n",
    "            continue\n",
    "        output_list.append(data)\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "inventoryData = dbtoList(inventory)\n",
    "orderData = dbtoList(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown\n",
    "\n",
    "class Supervised_Models:\n",
    "    # Location Prediction Model\n",
    "    def predict_location(input_data):\n",
    "        with open('../../Supervised_models/Samuel/storage_prediction_model.pkl', 'rb') as file:\n",
    "            storage_prediction_model = pickle.load(file)\n",
    "            \n",
    "        categorical_features = {\n",
    "            'Priority': ['High','Low','Medium'],\n",
    "            'Product_Type': ['Clothing','Technology','Other','Sports and Fitness'],\n",
    "            'Size': ['Large','Medium','Small']\n",
    "        }\n",
    "        numerical_features = ['Order_Quantity', 'Weight']\n",
    "        one_hot_columns = []\n",
    "        \n",
    "        for feature, values in categorical_features.items():\n",
    "            for value in values:\n",
    "                one_hot_columns.append(f\"{feature}_{value}\")\n",
    "            \n",
    "        # Combine with numerical features to get all feature names\n",
    "        all_feature_names = one_hot_columns + numerical_features\n",
    "\n",
    "        features_dict = {col: 0 for col in all_feature_names}\n",
    "    \n",
    "        # Set one-hot encoded features\n",
    "        for feature, values in categorical_features.items():\n",
    "            if feature in input_data:\n",
    "                selected_value = input_data[feature]\n",
    "                one_hot_col = f\"{feature}_{selected_value}\"\n",
    "                if one_hot_col in features_dict:\n",
    "                    features_dict[one_hot_col] = 1\n",
    "    \n",
    "        # Set numerical features\n",
    "        for feature in numerical_features:\n",
    "            if feature in input_data:\n",
    "                features_dict[feature] = float(input_data[feature])\n",
    "        \n",
    "        # Convert to array in the correct order\n",
    "        features_array = np.array([features_dict[col] for col in all_feature_names]).reshape(1, -1)\n",
    "\n",
    "        prediction = storage_prediction_model.predict(features_array)\n",
    "        return prediction\n",
    "\n",
    "    def demand_forecast_preprocessor(order_data, inventory_data):\n",
    "        # Create Dataframe\n",
    "        order = pd.DataFrame(order_data)\n",
    "        inventory = pd.DataFrame(inventory_data)\n",
    "\n",
    "        # Ensure dates are in datetime format\n",
    "        order['DateOrdered'] = pd.to_datetime(order['DateOrdered'])\n",
    "        \n",
    "        # Extract Month (period or string, depending on preference)\n",
    "        order['OrderMonth'] = order['DateOrdered'].dt.to_period('M')\n",
    "        \n",
    "        # Merge with Category lookup table\n",
    "        merged_df = order.merge(inventory, on='ItemId', how='left')\n",
    "        \n",
    "        # Group and aggregate\n",
    "        result_df = (\n",
    "            merged_df\n",
    "            .groupby(['OrderMonth', 'Category', 'CustomerSegment'], as_index=False)\n",
    "            .agg(\n",
    "                AveragePrice=('Price', 'mean'),\n",
    "                AverageDiscount=('Discount', 'mean')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    # Demand forecast model\n",
    "    def predict_demand_forecast(input_data):\n",
    "        demand_forecast_model = joblib.load('../../Supervised_models/ShernFai/model/salesforecast(categories).pkl')\n",
    "        with open('../../Supervised_models/ShernFai/model/salesforecast_preprocessor.pkl', 'rb') as f:\n",
    "            preprocessor_data = pickle.load(f)\n",
    "\n",
    "        categories = {\n",
    "            \"Clothing\" : [\n",
    "                \"Cleats\",\n",
    "                \"Men's Footwear\",\n",
    "                \"Women's Apparel\"\n",
    "            ],\n",
    "            \"Technology\": [\n",
    "                \"Electronics\",\n",
    "                \"Video Games\",\n",
    "                \"Cameras\",\n",
    "                \"Computers\",\n",
    "            ],\n",
    "            \"Sports and Fitness\": [\n",
    "                \"Cardio Equipment\",\n",
    "                \"Indoor/Outdoor Games\",\n",
    "                \"Water Sports\",\n",
    "                \"Shop By Sport\",\n",
    "                \"Camping & Hiking\",\n",
    "                \"Fishing\"\n",
    "            ],\n",
    "            \"Other\": [\n",
    "                \"Garden\",\n",
    "                \"Pet Supplies\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        cat_keys = list(categories.keys())\n",
    "\n",
    "        # Extract preprocessor components\n",
    "        le_category = preprocessor_data['label_encoder_category']\n",
    "        reference_date = preprocessor_data['reference_date']\n",
    "        unique_categories = preprocessor_data['unique_categories']\n",
    "        feature_columns = preprocessor_data['feature_columns']\n",
    "\n",
    "        # Get data\n",
    "        category_name = input_data['category']\n",
    "        future_month = input_data['month']\n",
    "        avg_price = float(input_data['avg_price'])\n",
    "        customer_segment = input_data['customer_segment']\n",
    "        discount_rate = float(input_data['discount_rate'])\n",
    "        \n",
    "        # Parse the future date\n",
    "        future_date = pd.to_datetime(future_month)\n",
    "        \n",
    "        # Calculate time features for the future date\n",
    "        months_since_start = ((future_date - reference_date).days / 30.44)\n",
    "        \n",
    "        # Create test data with numerical time features\n",
    "        test_data = {\n",
    "            'Category Name': category_name,\n",
    "            'Average Product Price': avg_price,\n",
    "            'Customer Segment': customer_segment,\n",
    "            'Order Item Discount Rate': discount_rate,\n",
    "            # Time features (numerical - can handle ANY future date!)\n",
    "            'Year': future_date.year,\n",
    "            'Month': future_date.month,\n",
    "            'Quarter': future_date.quarter,\n",
    "            'Months_Since_Start': int(months_since_start),\n",
    "            'Month_Sin': np.sin(2 * np.pi * future_date.month / 12),\n",
    "            'Month_Cos': np.cos(2 * np.pi * future_date.month / 12),\n",
    "            'Year_Trend': future_date.year - reference_date.year\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        test_df = pd.DataFrame([test_data])\n",
    "        \n",
    "        # Handle unknown category\n",
    "        if category_name not in cat_keys:\n",
    "            print(f\"Unknown category '{category_name}' - using default: {cat_keys[0]}\")\n",
    "            test_df['Category Name'] = cat_keys[0]\n",
    "            category_name = cat_keys[0]\n",
    "        \n",
    "        # One-hot encode customer segment\n",
    "        test_df = pd.get_dummies(test_df, columns=['Customer Segment'], drop_first=True)\n",
    "        \n",
    "        # Ensure same columns as training (crucial!)\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        total = 0\n",
    "        num = len(categories[category_name])\n",
    "        for subclass in categories[category_name]:\n",
    "            test_df['Category Name'] = subclass\n",
    "            test_df['Category Name'] = le_category.transform(test_df['Category Name'])\n",
    "            total += demand_forecast_model.predict(test_df)\n",
    "        \n",
    "        avg_demand = total / num\n",
    "        \n",
    "        return avg_demand\n",
    "\n",
    "    def detect_anomalies(inventory_list):\n",
    "        anomalies_detected = []\n",
    "        for item in inventory_list:\n",
    "            current_location = item['Location']\n",
    "            predicted_location = Supervised_Models.predict_location({\n",
    "                \"Priority\": item['Priority'],\n",
    "                \"Product_Type\": item['Category'],\n",
    "                \"Size\": item['Size'],\n",
    "                \"Order_Quantity\": item['Quantity'],\n",
    "                \"Weight\": item['Weight']\n",
    "            })[0]\n",
    "\n",
    "            #print(f\"\\nCurrent Location: {current_location}\")\n",
    "            #print(f\"Predicted Location: {predicted_location}\")\n",
    "            if current_location != predicted_location:\n",
    "                #print(f\"Anomaly detected! Item id:{item['ItemId']} is stored at location {current_location} while it should be stored at {predicted_location}.\")\n",
    "                anomalies_detected.append({'ItemId': item['ItemId'], 'ItemName': item['ItemName'], 'CurrentLocation': current_location, 'PredictedLocation': predicted_location})\n",
    "\n",
    "        return anomalies_detected\n",
    "\n",
    "s = Supervised_Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "print(s.predict_location({\n",
    "    \"Priority\": \"Medium\",\n",
    "    \"Product_Type\": \"Sports and Fitness\",\n",
    "    \"Size\": \"Medium\",\n",
    "    \"Order_Quantity\": 12,\n",
    "    \"Weight\": 10.78\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.detect_anomalies(inventoryData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.predict_demand_forecast({\n",
    "    'category': \"Clothing\",\n",
    "    'month': \"2025-05\",\n",
    "    'avg_price': 10.0,\n",
    "    'customer_segment': \"Consumer\",\n",
    "    'discount_rate': 0.12\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To generate a precise and detailed overview, I would need the actual data contained within `{sales_data}`, `{product_categories_data}`, `{sales_volume_data}`, and `{product_revenue_data}`.\n",
       "\n",
       "However, I can provide the *structure* and *explain how this overview would be generated*, along with illustrative examples of what the output would look like once the data is provided and processed.\n",
       "\n",
       "---\n",
       "\n",
       "## Product Performance Overview (Past Month)\n",
       "\n",
       "This overview analyzes product performance across various dimensions to identify key trends, top performers, and areas for strategic focus.\n",
       "\n",
       "### 1. Top Products by Sales Volume & Revenue\n",
       "\n",
       "**Methodology:**\n",
       "Products would be ranked based on their total sales volume (units sold) and total revenue generated over the past month, drawing directly from `{sales_volume_data}` and `{product_revenue_data}`. The top 5-10 products in each category would typically be highlighted.\n",
       "\n",
       "**Illustrative Example Output:**\n",
       "\n",
       "| Rank | Product Name        | Category     | Sales Volume (Units) | Revenue (USD) |\n",
       "| :--- | :------------------ | :----------- | :------------------- | :------------ |\n",
       "| 1    | Ultra HD Smart TV   | Electronics  | 1,500                | $1,500,000    |\n",
       "| 2    | Premium Coffee Maker| Home Goods   | 2,200                | $220,000      |\n",
       "| 3    | Ergonomic Office Chair| Furniture    | 800                  | $160,000      |\n",
       "| 4    | Wireless Earbuds    | Electronics  | 3,000                | $150,000      |\n",
       "| 5    | Organic Cotton T-Shirt| Apparel      | 5,000                | $100,000      |\n",
       "| ...  | *(Additional Top Products)* | ...          | ...                  | ...           |\n",
       "\n",
       "**Key Insights:**\n",
       "*   Identify high-value items (e.g., Ultra HD Smart TV) that drive significant revenue despite lower unit sales.\n",
       "*   Recognize high-volume, potentially lower-margin items (e.g., Organic Cotton T-Shirt) that indicate broad appeal.\n",
       "*   Understand which categories dominate the top-performer list.\n",
       "\n",
       "### 2. Product Performance by Category\n",
       "\n",
       "**Methodology:**\n",
       "Aggregate sales data, sales volume, and revenue for all products within each defined category (from `{product_categories_data}` linked with `{sales_data}`, `{sales_volume_data}`, and `{product_revenue_data}`). Demand can be inferred from sales volume and velocity.\n",
       "\n",
       "**Illustrative Example Output:**\n",
       "\n",
       "| Product Category | Total Revenue (USD) | Total Volume (Units) | Average Price Per Unit | Demand Trend (Inferred) | Key Observations                                     |\n",
       "| :--------------- | :------------------ | :------------------- | :--------------------- | :---------------------- | :--------------------------------------------------- |\n",
       "| **Electronics**  | $2,100,000          | 6,700                | $313.43                | High & Growing          | Strong revenue driver, high average price points.    |\n",
       "| **Apparel**      | $350,000            | 12,500               | $28.00                 | Steady                  | High volume, lower revenue per unit. Consistent sales.|\n",
       "| **Home Goods**   | $450,000            | 3,500                | $128.57                | Moderate                | Stable performance, good margin potential.           |\n",
       "| **Furniture**    | $300,000            | 1,200                | $250.00                | Moderate                | Fewer units, but high value. Seasonally influenced?  |\n",
       "| **Books**        | $80,000             | 4,000                | $20.00                 | Declining               | Lowest revenue, consistent volume but slowing down.  |\n",
       "| ...              | *(Additional Categories)* | ...                  | ...                    | ...                     | ...                                                  |\n",
       "\n",
       "**Key Insights:**\n",
       "*   **Electronics** are the primary revenue generator.\n",
       "*   **Apparel** drives significant unit sales, indicating broad market reach.\n",
       "*   **Books** show a concerning demand trend, potentially requiring promotional strategies or review.\n",
       "*   Average price per unit helps understand pricing strategy and market positioning across categories.\n",
       "\n",
       "### 3. Sales by Product (Detailed Summary)\n",
       "\n",
       "**Methodology:**\n",
       "For each individual product, retrieve and summarize its total revenue from `{product_revenue_data}`, total volume sold from `{sales_volume_data}`, and calculate the average price (Revenue / Volume).\n",
       "\n",
       "**Illustrative Example Output:**\n",
       "\n",
       "| Product ID | Product Name            | Category     | Total Revenue (USD) | Volume Sold (Units) | Average Price (USD) |\n",
       "| :--------- | :---------------------- | :----------- | :------------------ | :------------------ | :------------------ |\n",
       "| P001       | Ultra HD Smart TV       | Electronics  | $1,500,000          | 1,500               | $1,000.00           |\n",
       "| P002       | Premium Coffee Maker    | Home Goods   | $220,000            | 2,200               | $100.00             |\n",
       "| P003       | Ergonomic Office Chair  | Furniture    | $160,000            | 800                 | $200.00             |\n",
       "| P004       | Wireless Earbuds        | Electronics  | $150,000            | 3,000               | $50.00              |\n",
       "| P005       | Organic Cotton T-Shirt  | Apparel      | $100,000            | 5,000               | $20.00              |\n",
       "| P006       | Classic Fiction Novel   | Books        | $15,000             | 1,000               | $15.00              |\n",
       "| P007       | Smart Home Hub          | Electronics  | $400,000            | 1,200               | $333.33             |\n",
       "| ...        | *(All Products Listed)* | ...          | ...                 | ...                 | ...                 |\n",
       "\n",
       "**Key Insights:**\n",
       "*   Provides a granular view of each product's contribution.\n",
       "*   Helps identify individual products that might be underperforming within a strong category, or surprisingly overperforming in a weak one.\n",
       "*   Critical for inventory management, procurement, and targeted marketing campaigns for specific SKUs.\n",
       "\n",
       "---\n",
       "\n",
       "**Next Steps (with actual data):**\n",
       "\n",
       "Once the actual data is provided, I can process it to:\n",
       "1.  Generate precise tables and summaries as outlined above.\n",
       "2.  Provide specific, data-driven recommendations for inventory, marketing, and pricing strategies.\n",
       "3.  Identify any outliers or anomalies in sales performance that warrant further investigation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Product Overview: This section summarizes the overall performance of products\n",
    "product_overview = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate an overview of products based on the following:\n",
    "\n",
    "1. **Top Products**: Identify the top-selling products by sales volume and revenue over the past month.\n",
    "2. **Product Performance**: Analyze the performance of each product category in terms of sales, demand, and revenue.\n",
    "3. **Sales by Product**: Present a summary of sales for each product, including revenue, volume sold, and average price.\n",
    "\n",
    "Data:\n",
    "- Sales Data: {sales_data}\n",
    "- Product Categories: {product_categories_data}\n",
    "- Product Sales Volume: {sales_volume_data}\n",
    "- Product Revenue: {product_revenue_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_overview.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To provide precise insights on the distribution of sales across categories, the actual data for `sales_volume_by_category_data`, `revenue_by_category_data`, and `category_performance_data` is required.\n",
       "\n",
       "However, I can outline *how* these insights would be generated and what *types* of conclusions could be drawn once the data is provided. Please replace the placeholders with your actual sales data to get the specific analysis.\n",
       "\n",
       "---\n",
       "\n",
       "**Insights on Sales Distribution Across Categories (Framework for Analysis)**\n",
       "\n",
       "**Data Required:**\n",
       "\n",
       "*   **`sales_volume_by_category_data`**: e.g., `{\"Electronics\": 1500, \"Apparel\": 2200, \"Home Goods\": 800, \"Books\": 1000, \"Food & Beverage\": 3500}`\n",
       "*   **`revenue_by_category_data`**: e.g., `{\"Electronics\": 350000, \"Apparel\": 120000, \"Home Goods\": 90000, \"Books\": 25000, \"Food & Beverage\": 70000}`\n",
       "*   **`category_performance_data`**: This would ideally be a more detailed structure, possibly including trends, growth rates, and specific demand metrics.\n",
       "    *   Example for a single category: `{\"Electronics\": {\"SalesGrowthMonthOverMonth\": \"10%\", \"RevenueGrowthMonthOverMonth\": \"15%\", \"CustomerDemandScore\": \"High (4.5/5 reviews, frequent searches)\"}}`\n",
       "\n",
       "---\n",
       "\n",
       "**Analysis & Insights:**\n",
       "\n",
       "Once the data is populated, we would perform the following analysis:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Category-wise Sales Volume\n",
       "\n",
       "**Analysis:**\n",
       "We would sum the total sales volume across all product categories to get an overall picture of transactional activity. Then, we would break down the units sold by each category.\n",
       "\n",
       "**Expected Insights:**\n",
       "*   **High Volume Categories:** Identify which categories move the most units. This indicates products with high transactional frequency or broad appeal. (e.g., if `Food & Beverage` has the highest volume, it suggests many small, frequent purchases).\n",
       "*   **Low Volume Categories:** Pinpoint categories with fewer unit sales. These might be niche products, higher-priced items, or items with longer purchase cycles.\n",
       "*   **Volume Distribution:** Understand if sales volume is concentrated in a few categories or evenly distributed across many.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Category-wise Revenue\n",
       "\n",
       "**Analysis:**\n",
       "We would display the total revenue generated from each product category over the past month, allowing for a clear understanding of the monetary contribution of each segment.\n",
       "\n",
       "**Expected Insights:**\n",
       "*   **Revenue Drivers:** Clearly identify the \"cash cow\" categories that bring in the most money. (e.g., if `Electronics` has the highest revenue, it's a key financial pillar).\n",
       "*   **Revenue vs. Volume Discrepancy:**\n",
       "    *   **High Revenue, Moderate/Low Volume:** This suggests high-value or high-margin products (e.g., `Electronics` might have lower volume than `Food & Beverage` but significantly higher revenue). These are often critical for profitability.\n",
       "    *   **High Volume, Moderate/Low Revenue:** Indicates commodity-like products or items with lower price points/margins (e.g., `Food & Beverage` might have high volume but lower total revenue compared to `Electronics`). These contribute to customer traffic and basket size.\n",
       "*   **Profitability Potential:** Revenue figures are crucial for assessing the financial health and potential of each category.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Category-wise Performance (Sales, Revenue, Customer Demand)\n",
       "\n",
       "**Analysis:**\n",
       "This section would combine the volume and revenue data with specific performance metrics related to customer demand and growth trends.\n",
       "\n",
       "**Expected Insights:**\n",
       "\n",
       "*   **Best Performing Categories:**\n",
       "    *   **Definition:** These categories would show a strong positive correlation across high sales volume, high revenue, and robust customer demand.\n",
       "    *   **Characteristics:**\n",
       "        *   **High Sales/Revenue Growth:** Consistently increasing unit sales and monetary value month-over-month.\n",
       "        *   **Strong Customer Demand:** Indicated by high search interest, good conversion rates, positive customer reviews, low return rates, and potentially high repeat purchase rates.\n",
       "    *   **Example:** If `Electronics` shows high revenue, steady sales growth, and a high \"Customer Demand Score\" (reflecting strong interest and satisfaction), it would be a top performer.\n",
       "\n",
       "*   **Underperforming Categories:**\n",
       "    *   **Definition:** Categories with stagnant or declining sales volume, low revenue contribution, and/or waning customer interest.\n",
       "    *   **Characteristics:**\n",
       "        *   Low or negative sales/revenue growth.\n",
       "        *   Low customer engagement, poor reviews, high return rates, or declining search trends.\n",
       "    *   **Example:** If `Books` have low volume, low revenue, and \"Customer Demand Score\" indicating declining interest, it would be an underperformer.\n",
       "\n",
       "*   **Emerging or Niche Performers:**\n",
       "    *   **Definition:** Categories that might not be top in absolute volume or revenue yet but show significant positive trends in growth or demand.\n",
       "    *   **Characteristics:** Rapid month-over-month growth in sales/revenue, sudden spikes in customer interest or searches, positive early feedback.\n",
       "    *   **Example:** A new category like \"Sustainable Living\" might have lower absolute numbers but show a \"200% MoM growth\" in demand and sales, marking it as an emerging opportunity.\n",
       "\n",
       "---\n",
       "\n",
       "**Overall Insights & Key Takeaways (Upon Data Provision):**\n",
       "\n",
       "Once the actual data is provided, the combined analysis would allow us to:\n",
       "\n",
       "1.  **Identify Core Business Drivers:** Pinpoint the 2-3 categories that are the absolute backbone of your sales and revenue.\n",
       "2.  **Uncover Hidden Gems:** Discover categories that, despite lower volume, yield high revenue (high-margin products).\n",
       "3.  **Spot Areas for Improvement:** Clearly see which categories are lagging and require intervention (e.g., marketing boost, pricing adjustment, product line review, inventory reduction).\n",
       "4.  **Understand Customer Preferences:** Gain a clearer picture of where genuine customer interest and purchasing power lie.\n",
       "5.  **Inform Strategic Decisions:** Guide decisions on inventory management, marketing budget allocation, product development, and resource deployment across categories.\n",
       "\n",
       "---\n",
       "\n",
       "**To get specific, actionable insights, please provide your sales, revenue, and performance data for each category.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Category Distribution: This section analyzes the distribution of sales across categories\n",
    "category_distribution = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate insights on the distribution of sales across categories based on the following:\n",
    "\n",
    "1. **Category-wise Sales Volume**: Summarize the total sales volume across all product categories.\n",
    "2. **Category-wise Revenue**: Display the total revenue generated from each product category over the past month.\n",
    "3. **Category-wise Performance**: Provide insights on which product categories are performing the best in terms of sales, revenue, and customer demand.\n",
    "\n",
    "Data:\n",
    "- Sales Volume by Category: {sales_volume_by_category_data}\n",
    "- Revenue by Category: {revenue_by_category_data}\n",
    "- Product Category Performance: {category_performance_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(category_distribution.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Usage Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To generate a comprehensive product usage forecast, I first need to define and simulate the `historical_sales_data`, `usage_probabilities`, `seasonal_sales_patterns_data`, and `current_inventory_data` as these were provided as placeholders.\n",
       "\n",
       "**Disclaimer:** The following forecast is based on *simulated data* and a simplified forecasting methodology. For real-world applications, actual granular data and more sophisticated time-series analysis (e.g., ARIMA, Prophet, exponential smoothing) would be required.\n",
       "\n",
       "---\n",
       "\n",
       "### Executive Summary\n",
       "\n",
       "This report provides a product usage forecast for the upcoming quarter (Q1 2024), covering sales predictions, overall demand, and recommended stock levels. Based on simulated historical data, Product A is expected to maintain its lead in sales and demand, followed by Product B and Product C, which shows significant growth potential but lower individual usage probability. Strategic ordering is recommended to ensure optimal stock levels and avoid both stockouts and excessive inventory.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Simulated Data Used for Forecast\n",
       "\n",
       "To demonstrate the methodology, I've created plausible data sets:\n",
       "\n",
       "**A. Historical Sales Data (Monthly for 2023)**\n",
       "\n",
       "| Month | Product A (Units) | Product B (Units) | Product C (Units) |\n",
       "| :---- | :------------------ | :------------------ | :------------------ |\n",
       "| Jan-23 | 95                  | 48                  | 18                  |\n",
       "| Feb-23 | 98                  | 47                  | 19                  |\n",
       "| Mar-23 | 102                 | 50                  | 22                  |\n",
       "| Apr-23 | 105                 | 52                  | 23                  |\n",
       "| May-23 | 108                 | 51                  | 24                  |\n",
       "| Jun-23 | 110                 | 53                  | 26                  |\n",
       "| Jul-23 | 107                 | 50                  | 25                  |\n",
       "| Aug-23 | 106                 | 49                  | 24                  |\n",
       "| Sep-23 | 103                 | 48                  | 22                  |\n",
       "| Oct-23 | 112                 | 54                  | 27                  |\n",
       "| Nov-23 | 115                 | 55                  | 28                  |\n",
       "| Dec-23 | 118                 | 56                  | 30                  |\n",
       "\n",
       "**B. Product Usage Probabilities**\n",
       "*(Interpretation: The probability that a sold unit of a product will be actively used or consumed within the forecast period.)*\n",
       "\n",
       "*   **Product A:** 0.95 (95% of sold units are typically used)\n",
       "*   **Product B:** 0.85 (85% of sold units are typically used)\n",
       "*   **Product C:** 0.70 (70% of sold units are typically used)\n",
       "\n",
       "**C. Seasonal Sales Patterns Data (Quarterly Multipliers)**\n",
       "*(Based on general observation, Q1 is often slower, Q2/Q3 stable, Q4 peak.)*\n",
       "\n",
       "*   **Q1 (Jan-Mar):** 0.90 (10% lower than average)\n",
       "*   **Q2 (Apr-Jun):** 1.05 (5% higher than average)\n",
       "*   **Q3 (Jul-Sep):** 1.00 (Average)\n",
       "*   **Q4 (Oct-Dec):** 1.15 (15% higher than average)\n",
       "\n",
       "**D. Current Stock Levels (As of End of Dec 2023)**\n",
       "\n",
       "*   **Product A:** 200 units\n",
       "*   **Product B:** 100 units\n",
       "*   **Product C:** 50 units\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Assumptions for Forecasting\n",
       "\n",
       "*   **Forecasting Period:** Q1 2024 (January, February, March)\n",
       "*   **Forecasting Method:**\n",
       "    *   **Base Sales:** Average monthly sales from the preceding year (2023) are used as a baseline.\n",
       "    *   **Trend:** A conservative overall growth trend of **+5%** year-over-year (applied to the quarterly average) is assumed for all products, reflecting general market expansion or internal initiatives.\n",
       "    *   **Seasonality:** The predefined quarterly multipliers are applied to adjust for seasonal fluctuations.\n",
       "*   **Safety Stock:** A **15% safety stock** buffer is added to the forecasted demand to mitigate against unforeseen demand spikes or supply chain delays.\n",
       "*   **Lead Time:** Assumed to be short enough that stock can be acquired to meet the Q1 demand by the start of the period.\n",
       "*   **Usage Probability Interpretation:** Directly applied as a multiplier to the sales forecast to derive effective usage demand.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Forecasting Methodology & Calculations\n",
       "\n",
       "#### Step 1: Calculate Average Monthly/Quarterly Historical Sales (2023)\n",
       "\n",
       "*   **Product A:** Sum = 1279 units. Average Monthly = 1279 / 12 = 106.58 units. Average Quarterly = 106.58 * 3 = **319.75 units.**\n",
       "*   **Product B:** Sum = 603 units. Average Monthly = 603 / 12 = 50.25 units. Average Quarterly = 50.25 * 3 = **150.75 units.**\n",
       "*   **Product C:** Sum = 288 units. Average Monthly = 288 / 12 = 24.00 units. Average Quarterly = 24.00 * 3 = **72.00 units.**\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Sales Forecast by Product (Q1 2024)\n",
       "\n",
       "**Formula:** `(Average Quarterly Sales 2023) * (1 + Annual Growth Trend) * Seasonal Multiplier (Q1)`\n",
       "\n",
       "*   **Product A:**\n",
       "    *   319.75 * (1 + 0.05) * 0.90\n",
       "    *   319.75 * 1.05 * 0.90 = **302.16 units ≈ 302 units**\n",
       "*   **Product B:**\n",
       "    *   150.75 * (1 + 0.05) * 0.90\n",
       "    *   150.75 * 1.05 * 0.90 = **142.46 units ≈ 142 units**\n",
       "*   **Product C:**\n",
       "    *   72.00 * (1 + 0.05) * 0.90\n",
       "    *   72.00 * 1.05 * 0.90 = **68.04 units ≈ 68 units**\n",
       "\n",
       "**Sales Forecast Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Sales (Units) |\n",
       "| :-------- | :----------------------- |\n",
       "| Product A | 302                      |\n",
       "| Product B | 142                      |\n",
       "| Product C | 68                       |\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Demand Forecast (Q1 2024)\n",
       "\n",
       "**Formula:** `Sales Forecast * Product Usage Probability`\n",
       "\n",
       "*   **Product A:**\n",
       "    *   302 units (Sales Forecast) * 0.95 (Usage Probability) = **286.9 units ≈ 287 units**\n",
       "*   **Product B:**\n",
       "    *   142 units (Sales Forecast) * 0.85 (Usage Probability) = **120.7 units ≈ 121 units**\n",
       "*   **Product C:**\n",
       "    *   68 units (Sales Forecast) * 0.70 (Usage Probability) = **47.6 units ≈ 48 units**\n",
       "\n",
       "**Demand Forecast Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Demand (Units) |\n",
       "| :-------- | :------------------------ |\n",
       "| Product A | 287                       |\n",
       "| Product B | 121                       |\n",
       "| Product C | 48                        |\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Future Stock Levels (Required to meet Q1 2024 Demand)\n",
       "\n",
       "**Formulas:**\n",
       "*   `Safety Stock = Forecasted Demand * 0.15`\n",
       "*   `Required Stock Level = Forecasted Demand + Safety Stock`\n",
       "*   `Units to Order = Required Stock Level - Current Stock Level` (If positive, order; if zero or negative, no order needed, or potentially surplus to manage).\n",
       "\n",
       "*Self-correction: The \"Future Stock Levels\" typically refers to the *target* stock level to have at the *start* of the period to cover the period's demand. The \"Units to Order\" is the action needed.*\n",
       "\n",
       "**A. Product A:**\n",
       "*   Demand: 287 units\n",
       "*   Safety Stock: 287 * 0.15 = 43.05 units ≈ 43 units\n",
       "*   **Required Stock Level (Target):** 287 + 43 = **330 units**\n",
       "*   Current Stock: 200 units\n",
       "*   **Units to Order:** 330 - 200 = **130 units**\n",
       "\n",
       "**B. Product B:**\n",
       "*   Demand: 121 units\n",
       "*   Safety Stock: 121 * 0.15 = 18.15 units ≈ 18 units\n",
       "*   **Required Stock Level (Target):** 121 + 18 = **139 units**\n",
       "*   Current Stock: 100 units\n",
       "*   **Units to Order:** 139 - 100 = **39 units**\n",
       "\n",
       "**C. Product C:**\n",
       "*   Demand: 48 units\n",
       "*   Safety Stock: 48 * 0.15 = 7.2 units ≈ 7 units\n",
       "*   **Required Stock Level (Target):** 48 + 7 = **55 units**\n",
       "*   Current Stock: 50 units\n",
       "*   **Units to Order:** 55 - 50 = **5 units**\n",
       "\n",
       "**Future Stock Levels & Ordering Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Demand (Units) | Safety Stock (Units) | Required Stock Level (Target) | Current Stock (Units) | Units to Order (Approx.) |\n",
       "| :-------- | :------------------------ | :------------------- | :---------------------------- | :-------------------- | :----------------------- |\n",
       "| Product A | 287                       | 43                   | 330                           | 200                   | 130                      |\n",
       "| Product B | 121                       | 18                   | 139                           | 100                   | 39                       |\n",
       "| Product C | 48                        | 7                    | 55                            | 50                    | 5                        |\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Recommendations and Next Steps\n",
       "\n",
       "1.  **Prioritize Product A:** It continues to be the highest demand product. Ensure its supply chain is robust to meet the forecasted 130 units needed for Q1.\n",
       "2.  **Monitor Product C:** While its forecasted sales and demand are lower, it has a lower usage probability (0.70), suggesting some units sold might not translate to immediate active use. The current stock is nearly sufficient, but 5 units are still needed. Its historical data shows strong growth, so continued monitoring for a higher growth trend in future forecasts might be warranted.\n",
       "3.  **Review Safety Stock Levels:** The 15% safety stock is a general assumption. For critical products or those with high demand variability or long lead times, a more dynamic safety stock calculation (e.g., based on forecast error and lead time variability) would be beneficial.\n",
       "4.  **Refine Forecasting Model:** For more accuracy, consider:\n",
       "    *   **More Granular Data:** Weekly or daily sales data can capture short-term trends.\n",
       "    *   **Advanced Models:** Time series analysis methods (ARIMA, Exponential Smoothing, Prophet) can better capture complex trends, seasonality, and cycles.\n",
       "    *   **External Factors:** Incorporate market trends, marketing campaigns, competitor activities, economic indicators, and holiday effects.\n",
       "    *   **Product Lifecycle:** Account for new product introductions, mature products, and products nearing end-of-life.\n",
       "5.  **Iterate and Adjust:** Forecasting is an ongoing process. Regularly review actual sales and demand against forecasts and adjust the model parameters accordingly for improved accuracy in subsequent periods.\n",
       "\n",
       "This structured forecast provides a solid basis for operational planning for Q1 2024."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Product Usage Forecast: This section forecasts the future usage of products based on historical sales\n",
    "product_usage_forecast = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate a product usage forecast for the upcoming period based on historical data and trends:\n",
    "\n",
    "1. **Sales Forecast by Product**: Predict the sales volume for each product in the next quarter/year.\n",
    "2. **Demand Forecast**: Provide a demand forecast for products based on historical sales, usage probabilities, and seasonal patterns.\n",
    "3. **Future Stock Levels**: Estimate the required stock levels for each product to meet forecasted demand.\n",
    "\n",
    "Data:\n",
    "- Historical Sales Data: {historical_sales_data}\n",
    "- Product Usage Data: {usage_probabilities}\n",
    "- Seasonal Patterns: {seasonal_sales_patterns_data}\n",
    "- Current Stock Levels: {current_inventory_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_usage_forecast.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\pickle.py:1760: UserWarning: [18:43:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\gbm\\../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Sales Data\n",
    "sales_data = orderData\n",
    "\n",
    "# Sales Predictions\n",
    "current_date = datetime.now()\n",
    "next_month_date = current_date + relativedelta(months=1)\n",
    "next_month_yearmonth = next_month_date.strftime(\"%Y-%m\")\n",
    "\n",
    "sales_pred_input = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "sales_predictions = []\n",
    "\n",
    "for index, row in sales_pred_input.iterrows():\n",
    "    sales_predictions.append({\n",
    "        'Category Name': row.Category,\n",
    "        'Customer Segment': row.CustomerSegment,\n",
    "        'Predicted Demand for next month': s.predict_demand_forecast({\n",
    "            'category': row.Category,\n",
    "            'month': next_month_yearmonth,\n",
    "            'avg_price': row.AveragePrice,\n",
    "            'customer_segment': row.CustomerSegment,\n",
    "            'discount_rate': row.AverageDiscount\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "# Product Categories\n",
    "product_categories = [\"Clothing\",\"Technology\",\"Sports and Fitness\",\"Other\"]\n",
    "\n",
    "# Current Inventory\n",
    "current_inventory = inventoryData\n",
    "\n",
    "# Usage Probabilities\n",
    "usage_probabilities = \"Currently empty. Please ignore this section for now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Insights Section\n",
    "section_sales_insights = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate a sales insights report that describes information for the following areas:\n",
    "\n",
    "1. Sales Trends: Summarize sales based on the provided data. Provide insights on which product categories are seeing the highest demand.\n",
    "2. Product Performance: Analyze the best-selling product categories by quantity. Highlight the top 3 performing categories.\n",
    "3. Product Demand Forecast: Based on the historical sales and usage probability, forecast the demand for the next month.\n",
    "4. Restocking or Discontinuation: Recommend which products should be restocked and which should be discontinued, based on sales trends and inventory levels.\n",
    "\n",
    "Data:\n",
    "- Historical sales data: {sales_data}\n",
    "- Sales volume predictions for next month: {sales_predictions}\n",
    "- Product categories: {product_categories}\n",
    "- Current inventory levels: {current_inventory}\n",
    "- Usage probabilities: {usage_probabilities}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_sales_insights.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "location_predictions = []\n",
    "for item in inventoryData:\n",
    "    location_predictions.append({\n",
    "        'Item Id': item['ItemId'],\n",
    "        'Current Location': item['Location'],\n",
    "        'Predicted Location': s.predict_location({\n",
    "            'Priority': item['Priority'],\n",
    "            'Product_Type': item['Category'],\n",
    "            'Size': item['Size'],\n",
    "            'Order_Quantity': item['Quantity'],\n",
    "            'Weight': item['Weight']\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "section_storage_optimizations = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Provide detailed storage optimization recommendations based on:\n",
    "\n",
    "1. Current storage utilization metrics\n",
    "2. Model-predicted optimal locations vs current locations\n",
    "3. List of items flagged for relocation, including:\n",
    "   - Current location\n",
    "   - Recommended location\n",
    "\n",
    "Data:\n",
    "{inventoryData}\n",
    "{location_predictions}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_storage_optimizations.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "section_anomalies_detected = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate an anomalies section that lists all detected storage anomalies detected in a table. Include each item's current location, predicted location, item id, and name.\n",
    "Include the reason for each anomaly.\n",
    "\n",
    "Data:\n",
    "{s.detect_anomalies(inventoryData)}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_anomalies_detected.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Markdown content\n",
    "monthly_report = f'''<h1 style=\"text-align:center;\">Monthly Report</h1><br>\n",
    "\n",
    "# Products Overview:\n",
    "section_products_overview.text\n",
    "\n",
    "# Category Distribution:\n",
    "section_category_distribution.text\n",
    "\n",
    "# Product Usage Forecast:\n",
    "section_product_usage.text\n",
    "\n",
    "# Sales Insights:\n",
    "{section_sales_insights.text}\n",
    "\n",
    "# Storage Optimizations:\n",
    "{section_storage_optimizations.text}\n",
    "\n",
    "# Anomalies Detected:\n",
    "{section_anomalies_detected.text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_summary = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Provide a brief and concise summary of the provided report, covering all the key points highlighted by each section. Highlight the important information for each section in a bullet list, with the final paragraph providing general insight on overall performance.\n",
    "\n",
    "Report:\n",
    "{monthly_report}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_summary.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "monthly_report = f\"\"\"# <h1 style=\"text-align:center;\">Monthly Report ({current_date.date()})</h1><br>\n",
    "\n",
    "# Products Overview:\n",
    "section_products_overview.text\n",
    "\n",
    "# Category Distribution:\n",
    "section_category_distribution.text\n",
    "\n",
    "# Product Usage Forecast:\n",
    "section_product_usage.text\n",
    "\n",
    "# Sales Insights:\n",
    "{section_sales_insights.text}\n",
    "\n",
    "# Storage Optimizations:\n",
    "{section_storage_optimizations.text}\n",
    "\n",
    "# Anomalies Detected:\n",
    "{section_anomalies_detected.text}\n",
    "\n",
    "# Summary:\n",
    "{section_summary.text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown_pdf import MarkdownPdf, Section\n",
    "\n",
    "pdf = MarkdownPdf(toc_level=1)\n",
    "pdf.add_section(Section(monthly_report)) # Add Section(md_content, user_css=css_content) for custom CSS\n",
    "pdf.save(f\"MonthlyReport_({current_date.date()}).pdf\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompting.ipynb",
   "toc_visible": true
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:it3100] *",
   "language": "python",
   "name": "conda-env-it3100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
