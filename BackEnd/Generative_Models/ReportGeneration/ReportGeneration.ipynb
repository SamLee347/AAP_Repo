{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeadDkMiISin",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# AI Applications Project: Automated Report Generation\n",
    "\n",
    "This notebook demonstrates an end-to-end automated report generation system that combines:\n",
    "- **Supervised Machine Learning Models** for predictions and analysis\n",
    "- **Generative AI** for natural language report creation  \n",
    "- **Database Integration** for real-time data processing\n",
    "- **PDF Generation** for professional report output\n",
    "\n",
    "## Features\n",
    "- 🔍 **Location Prediction**: Optimal storage location recommendations\n",
    "- 📊 **Sample Categorization**: Automated product classification\n",
    "- ⚠️ **Disposal Risk Analysis**: Identify items at risk of disposal\n",
    "- 📈 **Demand Forecasting**: Predict future product demand\n",
    "- 🚨 **Anomaly Detection**: Identify storage optimization opportunities\n",
    "- 📋 **Automated Report Generation**: Professional PDF reports with insights\n",
    "\n",
    "## Models Used\n",
    "- Gradient Boosting (Jason's Model)\n",
    "- Storage Prediction (Samuel's Model) \n",
    "- Disposal Risk Prediction (Kendrick's Model)\n",
    "- Sales Forecasting (ShernFai's Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0c13de5f68f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Importing the generative ai\n",
    "%pip install -U -q \"google-genai>=1.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "Before running this notebook, ensure you have the following packages installed:\n",
    "\n",
    "```bash\n",
    "pip install google-genai pandas numpy scikit-learn joblib sqlalchemy python-dateutil markdown-pdf\n",
    "```\n",
    "\n",
    "**Note:** This notebook requires:\n",
    "- Access to the supervised model files in the `Supervised_Models` directory\n",
    "- Database connection configured in `Database/db.py`  \n",
    "- Google API key for generative AI features\n",
    "\n",
    "**File Structure Expected:**\n",
    "```\n",
    "BackEnd/\n",
    "├── Generative_Models/\n",
    "│   └── ReportGeneration/\n",
    "│       └── ReportGeneration.ipynb (this file)\n",
    "├── Supervised_Models/\n",
    "│   ├── Jason/model/\n",
    "│   ├── Kendrick/\n",
    "│   ├── Samuel/\n",
    "│   └── ShernFai/model/\n",
    "└── Database/\n",
    "    └── db.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4YDYyfRYN7L"
   },
   "source": [
    "### Setting up API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8K1RpmMfh20"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "# Security Note: For production use, store API key as environment variable\n",
    "# Example: GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "# For development/demo purposes:\n",
    "GOOGLE_API_KEY = input(\"Enter your Google API key:\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ll79uwEK4uPJ"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-19 03:15:36,124 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2025-08-19 03:15:36,124 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,127 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2025-08-19 03:15:36,129 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,130 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2025-08-19 03:15:36,130 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,133 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-19 03:15:36,124 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,127 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2025-08-19 03:15:36,129 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,130 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2025-08-19 03:15:36,130 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-19 03:15:36,133 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-19 03:15:36,135 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-19 03:15:36,136 INFO sqlalchemy.engine.Engine [generated in 0.00108s] {}\n",
      "2025-08-19 03:15:36,135 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-19 03:15:36,136 INFO sqlalchemy.engine.Engine [generated in 0.00108s] {}\n",
      "2025-08-19 03:15:36,159 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-19 03:15:36,161 INFO sqlalchemy.engine.Engine [generated in 0.00135s] {}\n",
      "2025-08-19 03:15:36,163 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-08-19 03:15:36,159 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-19 03:15:36,161 INFO sqlalchemy.engine.Engine [generated in 0.00135s] {}\n",
      "2025-08-19 03:15:36,163 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuration\n",
    "DEBUG_MODE = False  # Set to True for debugging output\n",
    "\n",
    "# Add parent directories to path for module imports\n",
    "sys.path.append('../../')\n",
    "\n",
    "try:\n",
    "    from Database.db import SessionLocal\n",
    "    from Database_Table import Inventory, Order\n",
    "    \n",
    "    def getDbContent():\n",
    "        \"\"\"\n",
    "        Retrieves inventory and order data from the database.\n",
    "        Returns empty lists if database connection fails.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            session = SessionLocal()\n",
    "            inventory_records = session.query(Inventory).all()\n",
    "            order_records = session.query(Order).all()\n",
    "            session.close()\n",
    "            \n",
    "            if DEBUG_MODE:\n",
    "                print(f\"Successfully loaded {len(inventory_records)} inventory records\")\n",
    "                print(f\"Successfully loaded {len(order_records)} order records\")\n",
    "                \n",
    "            return inventory_records, order_records\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Database connection error: {e}\")\n",
    "            print(\"Using empty data - some features may not work\")\n",
    "            return [], []\n",
    "\n",
    "    inventory, order = getDbContent()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Database import error: {e}\")\n",
    "    print(\"Database modules not available - using empty data\")\n",
    "    inventory, order = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbtoList(records):\n",
    "    output_list = []\n",
    "    for r in records:\n",
    "        if isinstance(r, Inventory):\n",
    "            data = {\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"ItemName\": r.ItemName,\n",
    "                \"Category\": r.ItemCategory,\n",
    "                \"Quantity\": r.ItemQuantity, \n",
    "                \"UnitsSold\": r.UnitsSold,\n",
    "                \"Weight\": r.Weight, \n",
    "                \"Size\": r.Size,\n",
    "                \"Priority\": r.Priority, \n",
    "                \"Location\": r.Location,\n",
    "                \"Date\": r.Date, \n",
    "                \"Dispose\": r.Dispose                \n",
    "            }\n",
    "        elif isinstance(r, Order):\n",
    "            data = {\n",
    "                \"OrderId\": r.OrderId,\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"OrderQuantity\": r.OrderQuantity, \n",
    "                \"Sales\": r.Sales, \n",
    "                \"Price\": r.Price, \n",
    "                \"Discount\": r.Discount,\n",
    "                \"Profit\": r.Profit, \n",
    "                \"DateOrdered\": r.DateOrdered,\n",
    "                \"DateReceived\": r.DateReceived,\n",
    "                \"CustomerSegment\": r.CustomerSegment\n",
    "            }\n",
    "        else:\n",
    "            continue\n",
    "        output_list.append(data)\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "inventoryData = dbtoList(inventory)\n",
    "orderData = dbtoList(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "DEBUG_MODE = False  # Set to True for debugging output\n",
    "\n",
    "\n",
    "class Supervised_Models:\n",
    "    # Category mapping for sample categorization\n",
    "    CATEGORY_MAPPING = {\n",
    "        \"Apparel\": \"Clothing\",\n",
    "        \"Footwear\": \"Clothing\",\n",
    "        \"Discs Shop\": \"Technology\", \n",
    "        \"Technology\": \"Technology\",\n",
    "        \"Fitness\": \"Sports and Fitness\",\n",
    "        \"Outdoors\": \"Sports and Fitness\", \n",
    "        \"Golf\": \"Sports and Fitness\",\n",
    "        \"Health and Beauty\": \"Other\",\n",
    "        \"Pet Shop\": \"Other\",\n",
    "        \"Book Shop\": \"Other\",\n",
    "        \"Fan Shop\": \"Other\"\n",
    "    }\n",
    "    \n",
    "    # Reverse mapping for prediction decoding (assuming numeric labels 0-10)\n",
    "    LABEL_TO_CATEGORY = {\n",
    "        0: \"Apparel\",\n",
    "        1: \"Book Shop\", \n",
    "        2: \"Discs Shop\",\n",
    "        3: \"Fan Shop\",\n",
    "        4: \"Fitness\",\n",
    "        5: \"Footwear\",\n",
    "        6: \"Golf\",\n",
    "        7: \"Health and Beauty\",\n",
    "        8: \"Outdoors\", \n",
    "        9: \"Pet Shop\",\n",
    "        10: \"Technology\"\n",
    "    }\n",
    "\n",
    "    # Location Prediction Model\n",
    "    @staticmethod\n",
    "    def predict_location(input_data):\n",
    "        try:\n",
    "            # Use relative path from ReportGeneration directory\n",
    "            model_path = \"../../Supervised_Models/Samuel/storage_prediction_model.pkl\"\n",
    "            with open(model_path, \"rb\") as file:\n",
    "                storage_prediction_model = pickle.load(file)\n",
    "\n",
    "            categorical_features = {\n",
    "                \"Priority\": [\"High\", \"Low\", \"Medium\"],\n",
    "                \"Product_Type\": [\"Clothing\", \"Technology\", \"Other\", \"Sports and Fitness\"],\n",
    "                \"Size\": [\"Large\", \"Medium\", \"Small\"],\n",
    "            }\n",
    "            numerical_features = [\"Order_Quantity\", \"Weight\"]\n",
    "            one_hot_columns = []\n",
    "\n",
    "            for feature, values in categorical_features.items():\n",
    "                for value in values:\n",
    "                    one_hot_columns.append(f\"{feature}_{value}\")\n",
    "\n",
    "            all_feature_names = one_hot_columns + numerical_features\n",
    "\n",
    "            features_dict = {col: 0 for col in all_feature_names}\n",
    "\n",
    "            for feature, values in categorical_features.items():\n",
    "                if feature in input_data:\n",
    "                    selected_value = input_data[feature]\n",
    "                    one_hot_col = f\"{feature}_{selected_value}\"\n",
    "                    if one_hot_col in features_dict:\n",
    "                        features_dict[one_hot_col] = 1\n",
    "\n",
    "            for feature in numerical_features:\n",
    "                if feature in input_data:\n",
    "                    features_dict[feature] = float(input_data[feature])\n",
    "\n",
    "            features_array = np.array(\n",
    "                [features_dict[col] for col in all_feature_names]\n",
    "            ).reshape(1, -1)\n",
    "\n",
    "            prediction = storage_prediction_model.predict(features_array)\n",
    "            return prediction\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Storage prediction model file not found: {e}\")\n",
    "            return [\"Model not available\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in location prediction: {e}\")\n",
    "            return [\"Error occurred\"]\n",
    "\n",
    "    # Sample Categorization Model (Supervised Model 1)\n",
    "    @staticmethod\n",
    "    def predict_sample_category(input_data):\n",
    "        try:\n",
    "            # Use relative paths from ReportGeneration directory\n",
    "            model_path = \"../../Supervised_Models/Jason/model/gradient_boosting_model.pkl\"\n",
    "            encoder_path = \"../../Supervised_Models/Jason/model/label_encoder.pkl\"\n",
    "            \n",
    "            sample_categorization_model = joblib.load(model_path)\n",
    "            \n",
    "            input_df = pd.DataFrame([input_data])\n",
    "            prediction = sample_categorization_model.predict(input_df)\n",
    "            \n",
    "            if DEBUG_MODE:\n",
    "                print(f\"Raw prediction: {prediction}\")\n",
    "            \n",
    "            # Convert numeric prediction to category name\n",
    "            predicted_label = int(prediction[0]) if len(prediction) > 0 else 0\n",
    "            \n",
    "            # Get subcategory name\n",
    "            subcategory = Supervised_Models.LABEL_TO_CATEGORY.get(predicted_label, \"Fitness\")\n",
    "            \n",
    "            # Map to main category\n",
    "            main_category = Supervised_Models.CATEGORY_MAPPING.get(subcategory, \"Other\")\n",
    "            \n",
    "            if DEBUG_MODE:\n",
    "                print(f\"Predicted label: {predicted_label}\")\n",
    "                print(f\"Subcategory: {subcategory}\")\n",
    "                print(f\"Main category: {main_category}\")\n",
    "            \n",
    "            return {\n",
    "                \"subcategory\": subcategory,\n",
    "                \"main_category\": main_category,\n",
    "                \"prediction_confidence\": \"Model prediction\"\n",
    "            }\n",
    "                \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Sample categorization model file not found: {e}\")\n",
    "            return {\n",
    "                \"subcategory\": \"Model not available\",\n",
    "                \"main_category\": \"Other\",\n",
    "                \"prediction_confidence\": \"Error\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sample categorization: {e}\")\n",
    "            return {\n",
    "                \"subcategory\": \"Error occurred\", \n",
    "                \"main_category\": \"Other\",\n",
    "                \"prediction_confidence\": \"Error\"\n",
    "            }\n",
    "\n",
    "    # Disposal Risk Prediction Model (Supervised Model 2)\n",
    "    @staticmethod\n",
    "    def predict_disposal_risk(input_data):\n",
    "        try:\n",
    "            # Use relative path from ReportGeneration directory\n",
    "            model_path = \"../../Supervised_Models/Kendrick/best_model.joblib\"\n",
    "            \n",
    "            # Load the model\n",
    "            loaded_object = joblib.load(model_path)\n",
    "            \n",
    "            # Check if it's a dictionary containing the model or the model itself\n",
    "            if isinstance(loaded_object, dict):\n",
    "                if 'model' in loaded_object:\n",
    "                    disposal_risk_model = loaded_object['model']\n",
    "                elif 'best_model' in loaded_object:\n",
    "                    disposal_risk_model = loaded_object['best_model']\n",
    "                else:\n",
    "                    # Try to find any sklearn model in the dictionary\n",
    "                    for key, value in loaded_object.items():\n",
    "                        if hasattr(value, 'predict'):\n",
    "                            disposal_risk_model = value\n",
    "                            break\n",
    "                    else:\n",
    "                        raise ValueError(\"No valid model found in the loaded dictionary\")\n",
    "            else:\n",
    "                # Assume it's the model directly\n",
    "                disposal_risk_model = loaded_object\n",
    "            \n",
    "            # Ensure the model has a predict method\n",
    "            if not hasattr(disposal_risk_model, 'predict'):\n",
    "                raise ValueError(\"Loaded object does not have a predict method\")\n",
    "\n",
    "            input_df = pd.DataFrame([input_data])\n",
    "            prediction = disposal_risk_model.predict(input_df)\n",
    "            \n",
    "            # Convert prediction to meaningful output\n",
    "            risk_level = \"High Risk\" if prediction[0] > 0.5 else \"Low Risk\"\n",
    "            \n",
    "            return {\n",
    "                \"risk_prediction\": risk_level,\n",
    "                \"risk_score\": float(prediction[0]) if hasattr(prediction[0], '__float__') else prediction[0],\n",
    "                \"recommendation\": \"Consider disposal\" if prediction[0] > 0.5 else \"Keep in inventory\"\n",
    "            }\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Disposal risk model file not found: {e}\")\n",
    "            return {\n",
    "                \"risk_prediction\": \"Model not available\",\n",
    "                \"risk_score\": 0.0,\n",
    "                \"recommendation\": \"Manual assessment required\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error in disposal risk prediction: {e}\")\n",
    "            return {\n",
    "                \"risk_prediction\": \"Error occurred\",\n",
    "                \"risk_score\": 0.0, \n",
    "                \"recommendation\": \"Manual assessment required\"\n",
    "            }\n",
    "\n",
    "    # Demand Forecast Preprocessing\n",
    "    @staticmethod\n",
    "    def demand_forecast_preprocessor(order_data, inventory_data):\n",
    "        try:\n",
    "            # Create DataFrames\n",
    "            order = pd.DataFrame(order_data)\n",
    "            inventory = pd.DataFrame(inventory_data)\n",
    "            \n",
    "            # Debug: Print column names to see what we have (optional for production)\n",
    "            if DEBUG_MODE:\n",
    "                print(\"Order columns:\", order.columns.tolist())\n",
    "                print(\"Inventory columns:\", inventory.columns.tolist())\n",
    "\n",
    "            # Ensure dates are in datetime format\n",
    "            if \"DateOrdered\" in order.columns:\n",
    "                order[\"DateOrdered\"] = pd.to_datetime(order[\"DateOrdered\"])\n",
    "                # Extract Month (period or string, depending on preference)\n",
    "                order[\"OrderMonth\"] = order[\"DateOrdered\"].dt.to_period(\"M\")\n",
    "            else:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\"Warning: DateOrdered column not found, creating dummy OrderMonth\")\n",
    "                order[\"OrderMonth\"] = \"2025-01\"  # Default value\n",
    "\n",
    "            # Handle Category column - inventory has ItemCategory, orders might not have category\n",
    "            if \"ItemCategory\" in inventory.columns:\n",
    "                inventory[\"Category\"] = inventory[\"ItemCategory\"]\n",
    "            elif \"Category\" not in inventory.columns:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\"Warning: No category column found in inventory, setting to 'Unknown'\")\n",
    "                inventory[\"Category\"] = \"Unknown\"\n",
    "\n",
    "            # Add Category to orders if missing (will be filled from inventory after merge)\n",
    "            if \"Category\" not in order.columns:\n",
    "                order[\"Category\"] = None\n",
    "\n",
    "            # Handle CustomerSegment - make sure it exists\n",
    "            if \"CustomerSegment\" not in order.columns:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\"Warning: CustomerSegment not found, setting to 'Consumer'\")\n",
    "                order[\"CustomerSegment\"] = \"Consumer\"\n",
    "\n",
    "            # Handle Price and Discount - make sure they exist\n",
    "            if \"Price\" not in order.columns:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\"Warning: Price not found in order data, setting to 0\")\n",
    "                order[\"Price\"] = 0.0\n",
    "                \n",
    "            if \"Discount\" not in order.columns:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\"Warning: Discount not found in order data, setting to 0\")\n",
    "                order[\"Discount\"] = 0.0\n",
    "\n",
    "            # Merge with inventory to get category information\n",
    "            merged_df = order.merge(inventory[[\"ItemId\", \"Category\"]], on=\"ItemId\", how=\"left\", suffixes=('', '_inv'))\n",
    "            \n",
    "            # Use inventory category if order category is missing\n",
    "            if \"Category_inv\" in merged_df.columns:\n",
    "                merged_df[\"Category\"] = merged_df[\"Category_inv\"].fillna(merged_df[\"Category\"])\n",
    "                merged_df = merged_df.drop(\"Category_inv\", axis=1)\n",
    "            \n",
    "            # Fill any remaining missing values\n",
    "            merged_df[\"Category\"] = merged_df[\"Category\"].fillna(\"Unknown\")\n",
    "            merged_df[\"CustomerSegment\"] = merged_df[\"CustomerSegment\"].fillna(\"Consumer\")\n",
    "            merged_df[\"Price\"] = merged_df[\"Price\"].fillna(0.0)\n",
    "            merged_df[\"Discount\"] = merged_df[\"Discount\"].fillna(0.0)\n",
    "\n",
    "            # Group and aggregate\n",
    "            result_df = merged_df.groupby(\n",
    "                [\"OrderMonth\", \"Category\", \"CustomerSegment\"], as_index=False\n",
    "            ).agg(AveragePrice=(\"Price\", \"mean\"), AverageDiscount=(\"Discount\", \"mean\"))\n",
    "\n",
    "            return result_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in demand forecast preprocessing: {e}\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "    # Demand forecast model\n",
    "    @staticmethod\n",
    "    def predict_demand_forecast(input_data):\n",
    "        try:\n",
    "            # Use relative paths from ReportGeneration directory\n",
    "            model_path = \"../../Supervised_Models/ShernFai/model/salesforecast(categories).pkl\"\n",
    "            preprocessor_path = \"../../Supervised_Models/ShernFai/model/salesforecast_preprocessor.pkl\"\n",
    "            \n",
    "            demand_forecast_model = joblib.load(model_path)\n",
    "            with open(preprocessor_path, \"rb\") as f:\n",
    "                preprocessor_data = pickle.load(f)\n",
    "\n",
    "            categories = {\n",
    "                \"Clothing\": [\"Cleats\", \"Men's Footwear\", \"Women's Apparel\"],\n",
    "                \"Technology\": [\n",
    "                    \"Electronics\",\n",
    "                    \"Video Games\",\n",
    "                    \"Cameras\",\n",
    "                    \"Computers\",\n",
    "                ],\n",
    "                \"Sports and Fitness\": [\n",
    "                    \"Cardio Equipment\",\n",
    "                    \"Indoor/Outdoor Games\",\n",
    "                    \"Water Sports\",\n",
    "                    \"Shop By Sport\",\n",
    "                    \"Camping & Hiking\",\n",
    "                    \"Fishing\",\n",
    "                ],\n",
    "                \"Other\": [\"Garden\", \"Pet Supplies\"],\n",
    "            }\n",
    "\n",
    "            cat_keys = list(categories.keys())\n",
    "\n",
    "            # Extract preprocessor components\n",
    "            le_category = preprocessor_data[\"label_encoder_category\"]\n",
    "            reference_date = preprocessor_data[\"reference_date\"]\n",
    "            unique_categories = preprocessor_data[\"unique_categories\"]\n",
    "            feature_columns = preprocessor_data[\"feature_columns\"]\n",
    "\n",
    "            # Get data\n",
    "            category_name = input_data[\"category\"]\n",
    "            future_month = input_data[\"month\"]\n",
    "            avg_price = float(input_data[\"avg_price\"])\n",
    "            customer_segment = input_data[\"customer_segment\"]\n",
    "            discount_rate = float(input_data[\"discount_rate\"])\n",
    "\n",
    "            # Parse the future date\n",
    "            future_date = pd.to_datetime(future_month)\n",
    "\n",
    "            # Calculate time features for the future date\n",
    "            months_since_start = (future_date - reference_date).days / 30.44\n",
    "\n",
    "            # Create test data with numerical time features\n",
    "            test_data = {\n",
    "                \"Category Name\": category_name,\n",
    "                \"Average Product Price\": avg_price,\n",
    "                \"Customer Segment\": customer_segment,\n",
    "                \"Order Item Discount Rate\": discount_rate,\n",
    "                # Time features (numerical - can handle ANY future date!)\n",
    "                \"Year\": future_date.year,\n",
    "                \"Month\": future_date.month,\n",
    "                \"Quarter\": future_date.quarter,\n",
    "                \"Months_Since_Start\": int(months_since_start),\n",
    "                \"Month_Sin\": np.sin(2 * np.pi * future_date.month / 12),\n",
    "                \"Month_Cos\": np.cos(2 * np.pi * future_date.month / 12),\n",
    "                \"Year_Trend\": future_date.year - reference_date.year,\n",
    "            }\n",
    "\n",
    "            # Create DataFrame\n",
    "            test_df = pd.DataFrame([test_data])\n",
    "\n",
    "            # Handle unknown category\n",
    "            if category_name not in cat_keys:\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"Unknown category '{category_name}' - using default: {cat_keys[0]}\")\n",
    "                test_df[\"Category Name\"] = cat_keys[0]\n",
    "                category_name = cat_keys[0]\n",
    "\n",
    "            # One-hot encode customer segment\n",
    "            test_df = pd.get_dummies(test_df, columns=[\"Customer Segment\"], drop_first=True)\n",
    "\n",
    "            # Ensure same columns as training (crucial!)\n",
    "            test_df = test_df.reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "            # Make prediction\n",
    "            total = 0\n",
    "            num = len(categories[category_name])\n",
    "            for subclass in categories[category_name]:\n",
    "                test_df[\"Category Name\"] = subclass\n",
    "                test_df[\"Category Name\"] = le_category.transform(test_df[\"Category Name\"])\n",
    "                total += demand_forecast_model.predict(test_df)\n",
    "\n",
    "            avg_demand = total / num\n",
    "            return avg_demand\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Demand forecast model file not found: {e}\")\n",
    "            return [0.0]  # Return default prediction\n",
    "        except Exception as e:\n",
    "            print(f\"Error in demand forecast prediction: {e}\")\n",
    "            return [0.0]  # Return default prediction\n",
    "\n",
    "    # Anomaly detection\n",
    "    @staticmethod\n",
    "    def detect_anomalies(inventory_list):\n",
    "        try:\n",
    "            anomalies_detected = []\n",
    "            for item in inventory_list:\n",
    "                current_location = item[\"Location\"]\n",
    "                predicted_location = Supervised_Models.predict_location(\n",
    "                    {\n",
    "                        \"Priority\": item[\"Priority\"],\n",
    "                        \"Product_Type\": item[\"Category\"],\n",
    "                        \"Size\": item[\"Size\"],\n",
    "                        \"Order_Quantity\": item[\"Quantity\"],\n",
    "                        \"Weight\": item[\"Weight\"],\n",
    "                    }\n",
    "                )[0]\n",
    "\n",
    "                if current_location != predicted_location:\n",
    "                    anomalies_detected.append(\n",
    "                        {\n",
    "                            \"ItemId\": item[\"ItemId\"],\n",
    "                            \"ItemName\": item[\"ItemName\"],\n",
    "                            \"CurrentLocation\": current_location,\n",
    "                            \"PredictedLocation\": predicted_location,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            return anomalies_detected\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in anomaly detection: {e}\")\n",
    "            return []  # Return empty list on error\n",
    "\n",
    "\n",
    "# Initialize the Supervised Models instance\n",
    "s = Supervised_Models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Supervised Models ===\n",
      "\n",
      "1. Testing Location Prediction Model:\n",
      "   ✓ Location prediction: ['B-3']\n",
      "\n",
      "2. Testing Sample Categorization Model:\n",
      "   ✓ Sample categorization:\n",
      "      • Subcategory: Fitness\n",
      "      • Main Category: Sports and Fitness\n",
      "      • Status: Model prediction\n",
      "\n",
      "3. Testing Disposal Risk Prediction Model:\n",
      "   ✓ Disposal risk prediction:\n",
      "      • Risk Level: High Risk\n",
      "      • Risk Score: 1.0\n",
      "      • Recommendation: Consider disposal\n",
      "\n",
      "4. Testing Demand Forecast Preprocessor:\n",
      "   ✓ Preprocessor output shape: (2, 5)\n",
      "\n",
      "5. Testing Demand Forecast Model:\n",
      "   ✓ Demand forecast: [186.10974]\n",
      "\n",
      "6. Testing Anomaly Detection:\n",
      "   ✓ Anomalies detected: 2 items\n",
      "\n",
      "=== All Tests Completed ===\n",
      "\n",
      "=== Testing Category Mapping Examples ===\n",
      "Example 1: Fitness → Sports and Fitness\n",
      "Example 2: Fitness → Sports and Fitness\n",
      "Example 3: Fitness → Sports and Fitness\n",
      "\n",
      "✓ Using real data: 2 inventory items, 2 orders\n",
      "Example 2: Fitness → Sports and Fitness\n",
      "Example 3: Fitness → Sports and Fitness\n",
      "\n",
      "✓ Using real data: 2 inventory items, 2 orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jason\\.conda\\envs\\aap_env\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test all Supervised Models\n",
    "print(\"=== Testing Supervised Models ===\\n\")\n",
    "\n",
    "# Test Location Prediction Model\n",
    "print(\"1. Testing Location Prediction Model:\")\n",
    "try:\n",
    "    location_result = s.predict_location({\n",
    "        \"Priority\": \"Medium\",\n",
    "        \"Product_Type\": \"Sports and Fitness\",\n",
    "        \"Size\": \"Medium\",\n",
    "        \"Order_Quantity\": 12,\n",
    "        \"Weight\": 10.78,\n",
    "    })\n",
    "    print(f\"   ✓ Location prediction: {location_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Location prediction failed: {e}\")\n",
    "\n",
    "# Test Sample Categorization Model\n",
    "print(\"\\n2. Testing Sample Categorization Model:\")\n",
    "try:\n",
    "    category_result = s.predict_sample_category({\n",
    "        \"Price\": 30.0,\n",
    "        \"Sales\": 1000,\n",
    "        \"Order_Profit\": 500,\n",
    "        \"ProductWeight\": 2.5,\n",
    "        \"Quantity\": 50,\n",
    "    })\n",
    "    print(f\"   ✓ Sample categorization:\")\n",
    "    print(f\"      • Subcategory: {category_result['subcategory']}\")\n",
    "    print(f\"      • Main Category: {category_result['main_category']}\")\n",
    "    print(f\"      • Status: {category_result['prediction_confidence']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Sample categorization failed: {e}\")\n",
    "\n",
    "# Test Disposal Risk Prediction Model\n",
    "print(\"\\n3. Testing Disposal Risk Prediction Model:\")\n",
    "try:\n",
    "    disposal_result = s.predict_disposal_risk({\n",
    "        \"Inventory_Level\": 150,\n",
    "        \"Inventory_Turnover\": 1.5,\n",
    "        \"Units_Sold\": 200,\n",
    "        \"Demand_Forecast\": 180,\n",
    "        \"Inventory_Lag_1\": 120,\n",
    "        \"Turnover_Lag_1\": 1.2,\n",
    "    })\n",
    "    print(f\"   ✓ Disposal risk prediction:\")\n",
    "    print(f\"      • Risk Level: {disposal_result['risk_prediction']}\")\n",
    "    print(f\"      • Risk Score: {disposal_result['risk_score']}\")\n",
    "    print(f\"      • Recommendation: {disposal_result['recommendation']}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Disposal risk prediction failed: {e}\")\n",
    "\n",
    "# Test Demand Forecast Preprocessor\n",
    "print(\"\\n4. Testing Demand Forecast Preprocessor:\")\n",
    "try:\n",
    "    # Sample test data\n",
    "    test_order_data = [\n",
    "        {\n",
    "            \"ItemId\": 101,\n",
    "            \"DateOrdered\": \"2025-01-10\",\n",
    "            \"Category\": \"Clothing\",\n",
    "            \"CustomerSegment\": \"Consumer\",\n",
    "            \"Price\": 30.0,\n",
    "            \"Discount\": 0.05,\n",
    "        },\n",
    "        {\n",
    "            \"ItemId\": 102,\n",
    "            \"DateOrdered\": \"2025-02-15\",\n",
    "            \"Category\": \"Technology\",\n",
    "            \"CustomerSegment\": \"Corporate\",\n",
    "            \"Price\": 200.0,\n",
    "            \"Discount\": 0.10,\n",
    "        },\n",
    "    ]\n",
    "    test_inventory_data = [\n",
    "        {\"ItemId\": 101, \"Category\": \"Clothing\", \"Price\": 30.0, \"Stock\": 50},\n",
    "        {\"ItemId\": 102, \"Category\": \"Technology\", \"Price\": 200.0, \"Stock\": 30},\n",
    "    ]\n",
    "    \n",
    "    preprocessed_result = s.demand_forecast_preprocessor(test_order_data, test_inventory_data)\n",
    "    print(f\"   ✓ Preprocessor output shape: {preprocessed_result.shape}\")\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"   Preprocessed data:\\n{preprocessed_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Demand forecast preprocessing failed: {e}\")\n",
    "\n",
    "# Test Demand Forecast Model\n",
    "print(\"\\n5. Testing Demand Forecast Model:\")\n",
    "try:\n",
    "    demand_result = s.predict_demand_forecast({\n",
    "        \"category\": \"Clothing\",\n",
    "        \"month\": \"2025-05\",\n",
    "        \"avg_price\": 10.0,\n",
    "        \"customer_segment\": \"Consumer\",\n",
    "        \"discount_rate\": 0.12,\n",
    "    })\n",
    "    print(f\"   ✓ Demand forecast: {demand_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Demand forecast failed: {e}\")\n",
    "\n",
    "# Test Anomaly Detection\n",
    "print(\"\\n6. Testing Anomaly Detection:\")\n",
    "try:\n",
    "    test_inventory = [\n",
    "        {\n",
    "            \"ItemId\": 1,\n",
    "            \"ItemName\": \"Test Item A\",\n",
    "            \"Priority\": \"High\",\n",
    "            \"Category\": \"Clothing\",\n",
    "            \"Size\": \"Large\",\n",
    "            \"Quantity\": 5,\n",
    "            \"Weight\": 8.5,\n",
    "            \"Location\": \"A1\",\n",
    "        },\n",
    "        {\n",
    "            \"ItemId\": 2,\n",
    "            \"ItemName\": \"Test Item B\",\n",
    "            \"Priority\": \"Low\",\n",
    "            \"Category\": \"Technology\",\n",
    "            \"Size\": \"Medium\",\n",
    "            \"Quantity\": 10,\n",
    "            \"Weight\": 3.4,\n",
    "            \"Location\": \"B2\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    anomalies_result = s.detect_anomalies(test_inventory)\n",
    "    print(f\"   ✓ Anomalies detected: {len(anomalies_result)} items\")\n",
    "    if DEBUG_MODE and anomalies_result:\n",
    "        print(f\"   Anomaly details: {anomalies_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Anomaly detection failed: {e}\")\n",
    "\n",
    "print(\"\\n=== All Tests Completed ===\")\n",
    "\n",
    "# Test with different categorization examples\n",
    "print(\"\\n=== Testing Category Mapping Examples ===\")\n",
    "test_examples = [\n",
    "    {\"Price\": 30.0, \"Sales\": 1000, \"Order_Profit\": 500, \"ProductWeight\": 2.5, \"Quantity\": 50},\n",
    "    {\"Price\": 150.0, \"Sales\": 500, \"Order_Profit\": 200, \"ProductWeight\": 1.2, \"Quantity\": 20},\n",
    "    {\"Price\": 80.0, \"Sales\": 800, \"Order_Profit\": 300, \"ProductWeight\": 5.0, \"Quantity\": 30}\n",
    "]\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    try:\n",
    "        result = s.predict_sample_category(example)\n",
    "        print(f\"Example {i}: {result['subcategory']} → {result['main_category']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Example {i}: Error - {e}\")\n",
    "\n",
    "# Use real data if available, otherwise use test data\n",
    "if len(inventoryData) > 0 and len(orderData) > 0:\n",
    "    print(f\"\\n✓ Using real data: {len(inventoryData)} inventory items, {len(orderData)} orders\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Using test data for demonstration\")\n",
    "    # Fallback to test data for the rest of the notebook\n",
    "    inventoryData = test_inventory\n",
    "    orderData = test_order_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Real Database Data Analysis ===\n",
      "\n",
      "📊 Database Status:\n",
      "   • Inventory records: 2\n",
      "   • Order records: 2\n",
      "\n",
      "📦 Inventory Data Sample:\n",
      "   • Sample item: {'ItemId': 101, 'Category': 'Clothing', 'Price': 30.0, 'Stock': 50}\n",
      "   • Categories found: ['Clothing', 'Technology']\n",
      "   • Storage locations: []\n",
      "\n",
      "🛒 Order Data Sample:\n",
      "   • Sample order: {'ItemId': 101, 'DateOrdered': '2025-01-10', 'Category': 'Clothing', 'CustomerSegment': 'Consumer', 'Price': 30.0, 'Discount': 0.05}\n",
      "   • Customer segments: ['Corporate', 'Consumer']\n",
      "\n",
      "✅ Ready to generate reports with real data!\n"
     ]
    }
   ],
   "source": [
    "# Check real database data\n",
    "print(\"=== Real Database Data Analysis ===\\n\")\n",
    "\n",
    "print(f\"📊 Database Status:\")\n",
    "print(f\"   • Inventory records: {len(inventoryData)}\")\n",
    "print(f\"   • Order records: {len(orderData)}\")\n",
    "\n",
    "if len(inventoryData) > 0:\n",
    "    print(f\"\\n📦 Inventory Data Sample:\")\n",
    "    print(f\"   • Sample item: {inventoryData[0]}\")\n",
    "    \n",
    "    # Check categories in inventory\n",
    "    categories = [item['Category'] for item in inventoryData if 'Category' in item]\n",
    "    unique_categories = list(set(categories))\n",
    "    print(f\"   • Categories found: {unique_categories}\")\n",
    "    \n",
    "    # Check locations\n",
    "    locations = [item['Location'] for item in inventoryData if 'Location' in item]\n",
    "    unique_locations = list(set(locations))\n",
    "    print(f\"   • Storage locations: {unique_locations}\")\n",
    "\n",
    "if len(orderData) > 0:\n",
    "    print(f\"\\n🛒 Order Data Sample:\")\n",
    "    print(f\"   • Sample order: {orderData[0]}\")\n",
    "    \n",
    "    # Check customer segments\n",
    "    segments = [order['CustomerSegment'] for order in orderData if 'CustomerSegment' in order]\n",
    "    unique_segments = list(set(segments))\n",
    "    print(f\"   • Customer segments: {unique_segments}\")\n",
    "\n",
    "print(f\"\\n✅ Ready to generate reports with real data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Full Automated Report with Real Data ===\n",
      "\n",
      "🗺️ Testing Location Predictions:\n",
      "   • Item 101: Unknown → B-6\n",
      "   • Item 102: Unknown → C-1\n",
      "\n",
      "📊 Testing Sample Categorization:\n",
      "   • Item 101: Fan Shop → Other\n",
      "   • Item 102: Fan Shop → Other\n",
      "\n",
      "⚠️ Testing Disposal Risk Analysis:\n",
      "   • Item 101: High Risk (Score: 1.00)\n",
      "   • Item 102: High Risk (Score: 1.00)\n",
      "\n",
      "📈 Testing Demand Forecasting:\n",
      "   • Found categories in data: ['Clothing', 'Technology']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jason\\.conda\\envs\\aap_env\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\jason\\.conda\\envs\\aap_env\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   • Clothing → Clothing: Predicted demand = 503.67\n",
      "   • Technology → Technology: Predicted demand = 429.55\n",
      "\n",
      "🔍 Testing Anomaly Detection:\n",
      "Error in anomaly detection: 'Location'\n",
      "   • Found 0 storage anomalies:\n",
      "\n",
      "🤖 Testing AI Report Generation:\n",
      "   ✓ AI-Generated Executive Summary:\n",
      "     This nascent business operates at a very limited scale, processing two orders from two inventory items, yet remarkably serves diverse product categories (Clothing, Technology) and customer segments (Corporate, Consumer). A critical operational gap exists with unknown storage locations for inventory. Prioritizing the establishment of clear storage and inventory management is crucial for the business's foundational stability and future growth.\n",
      "\n",
      "✅ Full Report Generation Test Completed!\n",
      "📊 System Status: Ready for production report generation with 2 inventory items and 2 orders\n"
     ]
    }
   ],
   "source": [
    "# Test Full Report Generation with Real Database Content\n",
    "print(\"=== Generating Full Automated Report with Real Data ===\\n\")\n",
    "\n",
    "try:\n",
    "    # 1. Test Location Predictions with Real Data\n",
    "    print(\"🗺️ Testing Location Predictions:\")\n",
    "    location_predictions = []\n",
    "    for item in inventoryData[:2]:  # Test with first 2 items\n",
    "        try:\n",
    "            prediction = s.predict_location({\n",
    "                'Priority': item.get('Priority', 'Medium'),\n",
    "                'Product_Type': item.get('Category', 'Other'),\n",
    "                'Size': item.get('Size', 'Medium'),\n",
    "                'Order_Quantity': item.get('Quantity', 1),\n",
    "                'Weight': item.get('Weight', 1.0)\n",
    "            })\n",
    "            location_predictions.append({\n",
    "                'ItemId': item['ItemId'],\n",
    "                'ItemName': item.get('ItemName', 'Unknown'),\n",
    "                'Current': item.get('Location', 'Unknown'),\n",
    "                'Predicted': prediction[0] if prediction else 'Unknown'\n",
    "            })\n",
    "            print(f\"   • Item {item['ItemId']}: {item.get('Location', 'Unknown')} → {prediction[0] if prediction else 'Unknown'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Error predicting location for item {item['ItemId']}: {e}\")\n",
    "    \n",
    "    # 2. Test Sample Categorization with Real Data\n",
    "    print(\"\\n📊 Testing Sample Categorization:\")\n",
    "    for item in inventoryData[:2]:  # Test with first 2 items\n",
    "        try:\n",
    "            # Prepare input data for categorization model\n",
    "            categorization_input = {\n",
    "                'Price': item.get('Price', 50.0),\n",
    "                'Sales': item.get('UnitsSold', 100),\n",
    "                'Order_Profit': item.get('UnitsSold', 100) * 0.3,  # Estimated profit\n",
    "                'ProductWeight': item.get('Weight', 2.0),\n",
    "                'Quantity': item.get('Quantity', 10)\n",
    "            }\n",
    "            \n",
    "            category_result = s.predict_sample_category(categorization_input)\n",
    "            print(f\"   • Item {item['ItemId']}: {category_result['subcategory']} → {category_result['main_category']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Error categorizing item {item['ItemId']}: {e}\")\n",
    "    \n",
    "    # 3. Test Disposal Risk with Real Data\n",
    "    print(\"\\n⚠️ Testing Disposal Risk Analysis:\")\n",
    "    for item in inventoryData[:2]:  # Test with first 2 items\n",
    "        try:\n",
    "            disposal_input = {\n",
    "                'Inventory_Level': item.get('Quantity', 50),\n",
    "                'Inventory_Turnover': 1.5,\n",
    "                'Units_Sold': item.get('UnitsSold', 100),\n",
    "                'Demand_Forecast': item.get('UnitsSold', 100) * 1.1,\n",
    "                'Inventory_Lag_1': item.get('Quantity', 50) * 0.8,\n",
    "                'Turnover_Lag_1': 1.2\n",
    "            }\n",
    "            \n",
    "            disposal_result = s.predict_disposal_risk(disposal_input)\n",
    "            print(f\"   • Item {item['ItemId']}: {disposal_result['risk_prediction']} (Score: {disposal_result['risk_score']:.2f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Error analyzing disposal risk for item {item['ItemId']}: {e}\")\n",
    "    \n",
    "    # 4. Test Demand Forecasting with Real Data\n",
    "    print(\"\\n📈 Testing Demand Forecasting:\")\n",
    "    try:\n",
    "        # Get unique categories from real data\n",
    "        real_categories = list(set([item.get('Category', 'Other') for item in inventoryData]))\n",
    "        print(f\"   • Found categories in data: {real_categories}\")\n",
    "        \n",
    "        # Map to our model categories\n",
    "        category_mapping = {\n",
    "            'Clothing': 'Clothing',\n",
    "            'Technology': 'Technology', \n",
    "            'Sports': 'Sports and Fitness',\n",
    "            'Other': 'Other'\n",
    "        }\n",
    "        \n",
    "        for category in real_categories[:2]:  # Test first 2 categories\n",
    "            try:\n",
    "                model_category = category_mapping.get(category, 'Other')\n",
    "                demand_result = s.predict_demand_forecast({\n",
    "                    'category': model_category,\n",
    "                    'month': '2025-09',\n",
    "                    'avg_price': 50.0,\n",
    "                    'customer_segment': 'Consumer',\n",
    "                    'discount_rate': 0.1\n",
    "                })\n",
    "                print(f\"   • {category} → {model_category}: Predicted demand = {demand_result[0]:.2f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ✗ Error forecasting demand for {category}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in demand forecasting: {e}\")\n",
    "    \n",
    "    # 5. Test Anomaly Detection with Real Data\n",
    "    print(\"\\n🔍 Testing Anomaly Detection:\")\n",
    "    try:\n",
    "        anomalies = s.detect_anomalies(inventoryData)\n",
    "        print(f\"   • Found {len(anomalies)} storage anomalies:\")\n",
    "        for anomaly in anomalies[:3]:  # Show first 3 anomalies\n",
    "            print(f\"     - Item {anomaly['ItemId']} ({anomaly['ItemName']}): {anomaly['CurrentLocation']} → {anomaly['PredictedLocation']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in anomaly detection: {e}\")\n",
    "    \n",
    "    # 6. Test AI Report Generation with Real Data Summary\n",
    "    print(\"\\n🤖 Testing AI Report Generation:\")\n",
    "    try:\n",
    "        # Create a sample report section with real data\n",
    "        data_summary = {\n",
    "            'total_inventory_items': len(inventoryData),\n",
    "            'total_orders': len(orderData),\n",
    "            'categories': list(set([item.get('Category', 'Unknown') for item in inventoryData])),\n",
    "            'locations': list(set([item.get('Location', 'Unknown') for item in inventoryData])),\n",
    "            'customer_segments': list(set([order.get('CustomerSegment', 'Unknown') for order in orderData]))\n",
    "        }\n",
    "        \n",
    "        sample_report = client.models.generate_content(\n",
    "            model=MODEL_ID,\n",
    "            contents=f'''Generate a brief executive summary based on this real business data:\n",
    "\n",
    "            Database Summary:\n",
    "            - Total inventory items: {data_summary['total_inventory_items']}\n",
    "            - Total orders: {data_summary['total_orders']}\n",
    "            - Product categories: {data_summary['categories']}\n",
    "            - Storage locations: {data_summary['locations']}\n",
    "            - Customer segments: {data_summary['customer_segments']}\n",
    "            \n",
    "            Provide a 2-3 sentence business insight.'''\n",
    "        )\n",
    "        \n",
    "        print(\"   ✓ AI-Generated Executive Summary:\")\n",
    "        print(f\"     {sample_report.text}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error in AI report generation: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ Full Report Generation Test Completed!\")\n",
    "    print(f\"📊 System Status: Ready for production report generation with {len(inventoryData)} inventory items and {len(orderData)} orders\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in full report generation test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRODUCTION REPORT GENERATION WITH MYSQL DATABASE ===\n",
      "\n",
      "🔌 Database Connection Status:\n",
      "2025-08-19 06:11:54,792 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-19 06:11:54,794 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-19 06:11:54,794 INFO sqlalchemy.engine.Engine [cached since 1.058e+04s ago] {}\n",
      "2025-08-19 06:11:54,797 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-19 06:11:54,797 INFO sqlalchemy.engine.Engine [cached since 1.058e+04s ago] {}\n",
      "2025-08-19 06:11:54,794 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-19 06:11:54,794 INFO sqlalchemy.engine.Engine [cached since 1.058e+04s ago] {}\n",
      "2025-08-19 06:11:54,797 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-19 06:11:54,797 INFO sqlalchemy.engine.Engine [cached since 1.058e+04s ago] {}\n",
      "2025-08-19 06:11:54,798 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-08-19 06:11:54,798 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "   ✓ MySQL Connection: ACTIVE\n",
      "   ✓ Inventory Records: 3 items\n",
      "   ✓ Order Records: 3 orders\n",
      "\n",
      "📊 Live Data Summary:\n",
      "   • Sample Inventory Item:\n",
      "     - ID: 101\n",
      "     - Name: Smartphone\n",
      "     - Category: Technology\n",
      "     - Location: A-1\n",
      "     - Quantity: 100\n",
      "   • Sample Order:\n",
      "     - Order ID: 1001\n",
      "     - Item ID: 101\n",
      "     - Customer Segment: Corporate\n",
      "     - Sales Amount: $5000\n",
      "\n",
      "🚀 AUTOMATED REPORT GENERATION PIPELINE:\n",
      "============================================================\n",
      "\n",
      "1️⃣ LOCATION OPTIMIZATION ANALYSIS\n",
      "   Item 101: A-1 → B-5 ⚠ NEEDS RELOCATION\n",
      "   Item 102: B-5 → B-5 ✓ OPTIMAL\n",
      "   Item 103: C-3 → A-5 ⚠ NEEDS RELOCATION\n",
      "\n",
      "   📊 Location Analysis Summary:\n",
      "   • Items analyzed: 3\n",
      "   • Storage issues found: 2\n",
      "   • Optimization rate: 33.3%\n",
      "\n",
      "2️⃣ CATEGORY PREDICTION & BUSINESS INSIGHTS\n",
      "   Item 101: Technology vs Fitness→Sports and Fitness ⚠ DIFFERENT\n",
      "   Item 102: Clothing vs Fan Shop→Other ⚠ DIFFERENT\n",
      "   Item 103: Clothing vs Fitness→Sports and Fitness ⚠ DIFFERENT\n",
      "\n",
      "   📊 Category Distribution:\n",
      "   • Sports and Fitness: 2 items (IDs: [101, 103])\n",
      "   • Other: 1 items (IDs: [102])\n",
      "\n",
      "3️⃣ DISPOSAL RISK ASSESSMENT\n",
      "   Item 101: High Risk (Score: 1.00) 🔴\n",
      "   Item 102: High Risk (Score: 1.00) 🔴\n",
      "   Item 103: High Risk (Score: 1.00) 🔴\n",
      "\n",
      "   📊 Risk Assessment Summary:\n",
      "   • High-risk items: 3\n",
      "   • Average risk score: 1.00\n",
      "   • Items needing attention: [101, 102, 103]\n",
      "\n",
      "4️⃣ DEMAND FORECASTING FOR NEXT MONTH\n",
      "   Categories in database: ['Clothing', 'Technology']\n",
      "   ✓ MySQL Connection: ACTIVE\n",
      "   ✓ Inventory Records: 3 items\n",
      "   ✓ Order Records: 3 orders\n",
      "\n",
      "📊 Live Data Summary:\n",
      "   • Sample Inventory Item:\n",
      "     - ID: 101\n",
      "     - Name: Smartphone\n",
      "     - Category: Technology\n",
      "     - Location: A-1\n",
      "     - Quantity: 100\n",
      "   • Sample Order:\n",
      "     - Order ID: 1001\n",
      "     - Item ID: 101\n",
      "     - Customer Segment: Corporate\n",
      "     - Sales Amount: $5000\n",
      "\n",
      "🚀 AUTOMATED REPORT GENERATION PIPELINE:\n",
      "============================================================\n",
      "\n",
      "1️⃣ LOCATION OPTIMIZATION ANALYSIS\n",
      "   Item 101: A-1 → B-5 ⚠ NEEDS RELOCATION\n",
      "   Item 102: B-5 → B-5 ✓ OPTIMAL\n",
      "   Item 103: C-3 → A-5 ⚠ NEEDS RELOCATION\n",
      "\n",
      "   📊 Location Analysis Summary:\n",
      "   • Items analyzed: 3\n",
      "   • Storage issues found: 2\n",
      "   • Optimization rate: 33.3%\n",
      "\n",
      "2️⃣ CATEGORY PREDICTION & BUSINESS INSIGHTS\n",
      "   Item 101: Technology vs Fitness→Sports and Fitness ⚠ DIFFERENT\n",
      "   Item 102: Clothing vs Fan Shop→Other ⚠ DIFFERENT\n",
      "   Item 103: Clothing vs Fitness→Sports and Fitness ⚠ DIFFERENT\n",
      "\n",
      "   📊 Category Distribution:\n",
      "   • Sports and Fitness: 2 items (IDs: [101, 103])\n",
      "   • Other: 1 items (IDs: [102])\n",
      "\n",
      "3️⃣ DISPOSAL RISK ASSESSMENT\n",
      "   Item 101: High Risk (Score: 1.00) 🔴\n",
      "   Item 102: High Risk (Score: 1.00) 🔴\n",
      "   Item 103: High Risk (Score: 1.00) 🔴\n",
      "\n",
      "   📊 Risk Assessment Summary:\n",
      "   • High-risk items: 3\n",
      "   • Average risk score: 1.00\n",
      "   • Items needing attention: [101, 102, 103]\n",
      "\n",
      "4️⃣ DEMAND FORECASTING FOR NEXT MONTH\n",
      "   Categories in database: ['Clothing', 'Technology']\n",
      "   Clothing → Clothing: 503.7 units (Avg Price: $50.00)   Clothing → Clothing: 503.7 units (Avg Price: $50.00)\n",
      "   Technology → Technology: 429.6 units (Avg Price: $50.00)\n",
      "\n",
      "   📊 Forecast Summary:\n",
      "   • Total predicted demand: 933.2 units\n",
      "   • Categories forecasted: 2\n",
      "\n",
      "   Technology → Technology: 429.6 units (Avg Price: $50.00)\n",
      "\n",
      "   📊 Forecast Summary:\n",
      "   • Total predicted demand: 933.2 units\n",
      "   • Categories forecasted: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jason\\.conda\\envs\\aap_env\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\jason\\.conda\\envs\\aap_env\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Full Automated Report Generation with MySQL Database\n",
    "print(\"=== PRODUCTION REPORT GENERATION WITH MYSQL DATABASE ===\\n\")\n",
    "\n",
    "# Verify database connection and fetch fresh data\n",
    "print(\"🔌 Database Connection Status:\")\n",
    "try:\n",
    "    # Get fresh data from MySQL database\n",
    "    session = SessionLocal()\n",
    "    fresh_inventory = session.query(Inventory).all()\n",
    "    fresh_orders = session.query(Order).all()\n",
    "    session.close()\n",
    "    \n",
    "    print(f\"   ✓ MySQL Connection: ACTIVE\")\n",
    "    print(f\"   ✓ Inventory Records: {len(fresh_inventory)} items\")\n",
    "    print(f\"   ✓ Order Records: {len(fresh_orders)} orders\")\n",
    "    \n",
    "    # Convert to working format\n",
    "    live_inventory_data = dbtoList(fresh_inventory)\n",
    "    live_order_data = dbtoList(fresh_orders)\n",
    "    \n",
    "    print(f\"\\n📊 Live Data Summary:\")\n",
    "    if live_inventory_data:\n",
    "        sample_inventory = live_inventory_data[0]\n",
    "        print(f\"   • Sample Inventory Item:\")\n",
    "        print(f\"     - ID: {sample_inventory.get('ItemId', 'N/A')}\")\n",
    "        print(f\"     - Name: {sample_inventory.get('ItemName', 'N/A')}\")\n",
    "        print(f\"     - Category: {sample_inventory.get('Category', 'N/A')}\")\n",
    "        print(f\"     - Location: {sample_inventory.get('Location', 'N/A')}\")\n",
    "        print(f\"     - Quantity: {sample_inventory.get('Quantity', 'N/A')}\")\n",
    "        \n",
    "    if live_order_data:\n",
    "        sample_order = live_order_data[0] \n",
    "        print(f\"   • Sample Order:\")\n",
    "        print(f\"     - Order ID: {sample_order.get('OrderId', 'N/A')}\")\n",
    "        print(f\"     - Item ID: {sample_order.get('ItemId', 'N/A')}\")\n",
    "        print(f\"     - Customer Segment: {sample_order.get('CustomerSegment', 'N/A')}\")\n",
    "        print(f\"     - Sales Amount: ${sample_order.get('Sales', 'N/A')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Database connection failed: {e}\")\n",
    "    print(\"   Using previously loaded data...\")\n",
    "    live_inventory_data = inventoryData\n",
    "    live_order_data = orderData\n",
    "\n",
    "print(f\"\\n🚀 AUTOMATED REPORT GENERATION PIPELINE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. LOCATION OPTIMIZATION ANALYSIS\n",
    "print(\"\\n1️⃣ LOCATION OPTIMIZATION ANALYSIS\")\n",
    "location_analysis = []\n",
    "storage_issues = 0\n",
    "\n",
    "for item in live_inventory_data[:5]:  # Analyze first 5 items\n",
    "    try:\n",
    "        current_location = item.get('Location', 'Unknown')\n",
    "        \n",
    "        # Predict optimal location\n",
    "        prediction_input = {\n",
    "            'Priority': item.get('Priority', 'Medium'),\n",
    "            'Product_Type': item.get('Category', 'Other'),\n",
    "            'Size': item.get('Size', 'Medium'),\n",
    "            'Order_Quantity': item.get('Quantity', 1),\n",
    "            'Weight': item.get('Weight', 1.0)\n",
    "        }\n",
    "        \n",
    "        predicted_location = s.predict_location(prediction_input)[0]\n",
    "        \n",
    "        is_optimized = current_location == predicted_location\n",
    "        if not is_optimized:\n",
    "            storage_issues += 1\n",
    "            \n",
    "        location_analysis.append({\n",
    "            'item_id': item.get('ItemId'),\n",
    "            'item_name': item.get('ItemName', 'Unknown')[:20],\n",
    "            'current': current_location,\n",
    "            'predicted': predicted_location,\n",
    "            'optimized': is_optimized\n",
    "        })\n",
    "        \n",
    "        status = \"✓ OPTIMAL\" if is_optimized else \"⚠ NEEDS RELOCATION\"\n",
    "        print(f\"   Item {item.get('ItemId')}: {current_location} → {predicted_location} {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error analyzing item {item.get('ItemId')}: {e}\")\n",
    "\n",
    "print(f\"\\n   📊 Location Analysis Summary:\")\n",
    "print(f\"   • Items analyzed: {len(location_analysis)}\")\n",
    "print(f\"   • Storage issues found: {storage_issues}\")\n",
    "print(f\"   • Optimization rate: {((len(location_analysis) - storage_issues) / len(location_analysis) * 100):.1f}%\")\n",
    "\n",
    "# 2. CATEGORY PREDICTION & BUSINESS INSIGHTS\n",
    "print(f\"\\n2️⃣ CATEGORY PREDICTION & BUSINESS INSIGHTS\")\n",
    "category_insights = {}\n",
    "\n",
    "for item in live_inventory_data[:3]:  # Analyze first 3 items\n",
    "    try:\n",
    "        # Prepare model input\n",
    "        category_input = {\n",
    "            'Price': float(item.get('Price', 50.0)) if item.get('Price') else 50.0,\n",
    "            'Sales': float(item.get('UnitsSold', 100)) if item.get('UnitsSold') else 100,\n",
    "            'Order_Profit': float(item.get('UnitsSold', 100)) * 0.3 if item.get('UnitsSold') else 30,\n",
    "            'ProductWeight': float(item.get('Weight', 2.0)) if item.get('Weight') else 2.0,\n",
    "            'Quantity': float(item.get('Quantity', 10)) if item.get('Quantity') else 10\n",
    "        }\n",
    "        \n",
    "        category_prediction = s.predict_sample_category(category_input)\n",
    "        actual_category = item.get('Category', 'Unknown')\n",
    "        \n",
    "        predicted_main = category_prediction.get('main_category', 'Other')\n",
    "        predicted_sub = category_prediction.get('subcategory', 'Unknown')\n",
    "        \n",
    "        # Track category insights\n",
    "        if predicted_main not in category_insights:\n",
    "            category_insights[predicted_main] = {'count': 0, 'items': []}\n",
    "        category_insights[predicted_main]['count'] += 1\n",
    "        category_insights[predicted_main]['items'].append(item.get('ItemId'))\n",
    "        \n",
    "        match_status = \"✓ MATCH\" if actual_category == predicted_main else \"⚠ DIFFERENT\"\n",
    "        print(f\"   Item {item.get('ItemId')}: {actual_category} vs {predicted_sub}→{predicted_main} {match_status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error categorizing item {item.get('ItemId')}: {e}\")\n",
    "\n",
    "print(f\"\\n   📊 Category Distribution:\")\n",
    "for category, data in category_insights.items():\n",
    "    print(f\"   • {category}: {data['count']} items (IDs: {data['items']})\")\n",
    "\n",
    "# 3. DISPOSAL RISK ASSESSMENT  \n",
    "print(f\"\\n3️⃣ DISPOSAL RISK ASSESSMENT\")\n",
    "high_risk_items = []\n",
    "total_risk_score = 0\n",
    "\n",
    "for item in live_inventory_data[:3]:\n",
    "    try:\n",
    "        disposal_input = {\n",
    "            'Inventory_Level': float(item.get('Quantity', 50)),\n",
    "            'Inventory_Turnover': 1.5,  # Default value\n",
    "            'Units_Sold': float(item.get('UnitsSold', 100)) if item.get('UnitsSold') else 100,\n",
    "            'Demand_Forecast': float(item.get('UnitsSold', 100)) * 1.1 if item.get('UnitsSold') else 110,\n",
    "            'Inventory_Lag_1': float(item.get('Quantity', 50)) * 0.8 if item.get('Quantity') else 40,\n",
    "            'Turnover_Lag_1': 1.2\n",
    "        }\n",
    "        \n",
    "        disposal_result = s.predict_disposal_risk(disposal_input)\n",
    "        risk_level = disposal_result.get('risk_prediction', 'Unknown')\n",
    "        risk_score = disposal_result.get('risk_score', 0.0)\n",
    "        \n",
    "        total_risk_score += risk_score\n",
    "        \n",
    "        if 'High Risk' in risk_level:\n",
    "            high_risk_items.append({\n",
    "                'id': item.get('ItemId'),\n",
    "                'name': item.get('ItemName', 'Unknown'),\n",
    "                'score': risk_score\n",
    "            })\n",
    "            \n",
    "        status_emoji = \"🔴\" if 'High Risk' in risk_level else \"🟢\"\n",
    "        print(f\"   Item {item.get('ItemId')}: {risk_level} (Score: {risk_score:.2f}) {status_emoji}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error assessing disposal risk for item {item.get('ItemId')}: {e}\")\n",
    "\n",
    "avg_risk = total_risk_score / len(live_inventory_data[:3]) if live_inventory_data else 0\n",
    "print(f\"\\n   📊 Risk Assessment Summary:\")\n",
    "print(f\"   • High-risk items: {len(high_risk_items)}\")\n",
    "print(f\"   • Average risk score: {avg_risk:.2f}\")\n",
    "print(f\"   • Items needing attention: {[item['id'] for item in high_risk_items]}\")\n",
    "\n",
    "# 4. DEMAND FORECASTING\n",
    "print(f\"\\n4️⃣ DEMAND FORECASTING FOR NEXT MONTH\")\n",
    "forecast_results = []\n",
    "\n",
    "try:\n",
    "    # Get unique categories from live data\n",
    "    live_categories = list(set([item.get('Category', 'Other') for item in live_inventory_data]))\n",
    "    print(f\"   Categories in database: {live_categories}\")\n",
    "    \n",
    "    # Map to model categories\n",
    "    category_mapping = {\n",
    "        'Clothing': 'Clothing',\n",
    "        'Technology': 'Technology',\n",
    "        'Sports': 'Sports and Fitness',\n",
    "        'Other': 'Other'\n",
    "    }\n",
    "    \n",
    "    for db_category in live_categories[:2]:  # Forecast for first 2 categories\n",
    "        try:\n",
    "            model_category = category_mapping.get(db_category, 'Other')\n",
    "            \n",
    "            # Calculate average price for this category\n",
    "            category_items = [item for item in live_inventory_data if item.get('Category') == db_category]\n",
    "            avg_price = 50.0  # Default\n",
    "            if category_items:\n",
    "                prices = [float(item.get('Price', 50.0)) for item in category_items if item.get('Price')]\n",
    "                if prices:\n",
    "                    avg_price = sum(prices) / len(prices)\n",
    "            \n",
    "            forecast_input = {\n",
    "                'category': model_category,\n",
    "                'month': '2025-09',  # Next month\n",
    "                'avg_price': avg_price,\n",
    "                'customer_segment': 'Consumer',\n",
    "                'discount_rate': 0.1\n",
    "            }\n",
    "            \n",
    "            predicted_demand = s.predict_demand_forecast(forecast_input)[0]\n",
    "            \n",
    "            forecast_results.append({\n",
    "                'category': db_category,\n",
    "                'model_category': model_category,\n",
    "                'predicted_demand': predicted_demand,\n",
    "                'avg_price': avg_price\n",
    "            })\n",
    "            \n",
    "            print(f\"   {db_category} → {model_category}: {predicted_demand:.1f} units (Avg Price: ${avg_price:.2f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ✗ Error forecasting {db_category}: {e}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Error in demand forecasting: {e}\")\n",
    "\n",
    "print(f\"\\n   📊 Forecast Summary:\")\n",
    "total_predicted = sum([result['predicted_demand'] for result in forecast_results])\n",
    "print(f\"   • Total predicted demand: {total_predicted:.1f} units\")\n",
    "print(f\"   • Categories forecasted: {len(forecast_results)}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "print(s.predict_location({\n",
    "    \"Priority\": \"Medium\",\n",
    "    \"Product_Type\": \"Sports and Fitness\",\n",
    "    \"Size\": \"Medium\",\n",
    "    \"Order_Quantity\": 12,\n",
    "    \"Weight\": 10.78\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.detect_anomalies(inventoryData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.predict_demand_forecast({\n",
    "    'category': \"Clothing\",\n",
    "    'month': \"2025-05\",\n",
    "    'avg_price': 10.0,\n",
    "    'customer_segment': \"Consumer\",\n",
    "    'discount_rate': 0.12\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Product Overview: This section summarizes the overall performance of products\u001b[39;00m\n\u001b[0;32m      2\u001b[0m product_overview \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mMODEL_ID,\n\u001b[0;32m      4\u001b[0m     contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m display(\u001b[43mMarkdown\u001b[49m(product_overview\u001b[38;5;241m.\u001b[39mtext))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "# Product Overview: This section summarizes the overall performance of products\n",
    "product_overview = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate an overview of products based on the following:\n",
    "\n",
    "1. **Top Products**: Identify the top-selling products by sales volume and revenue over the past month.\n",
    "2. **Product Performance**: Analyze the performance of each product category in terms of sales, demand, and revenue.\n",
    "3. **Sales by Product**: Present a summary of sales for each product, including revenue, volume sold, and average price.\n",
    "\n",
    "Data:\n",
    "- Sales Data: {sales_data}\n",
    "- Product Categories: {product_categories_data}\n",
    "- Product Sales Volume: {sales_volume_data}\n",
    "- Product Revenue: {product_revenue_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_overview.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To provide precise insights on the distribution of sales across categories, the actual data for `sales_volume_by_category_data`, `revenue_by_category_data`, and `category_performance_data` is required.\n",
       "\n",
       "However, I can outline *how* these insights would be generated and what *types* of conclusions could be drawn once the data is provided. Please replace the placeholders with your actual sales data to get the specific analysis.\n",
       "\n",
       "---\n",
       "\n",
       "**Insights on Sales Distribution Across Categories (Framework for Analysis)**\n",
       "\n",
       "**Data Required:**\n",
       "\n",
       "*   **`sales_volume_by_category_data`**: e.g., `{\"Electronics\": 1500, \"Apparel\": 2200, \"Home Goods\": 800, \"Books\": 1000, \"Food & Beverage\": 3500}`\n",
       "*   **`revenue_by_category_data`**: e.g., `{\"Electronics\": 350000, \"Apparel\": 120000, \"Home Goods\": 90000, \"Books\": 25000, \"Food & Beverage\": 70000}`\n",
       "*   **`category_performance_data`**: This would ideally be a more detailed structure, possibly including trends, growth rates, and specific demand metrics.\n",
       "    *   Example for a single category: `{\"Electronics\": {\"SalesGrowthMonthOverMonth\": \"10%\", \"RevenueGrowthMonthOverMonth\": \"15%\", \"CustomerDemandScore\": \"High (4.5/5 reviews, frequent searches)\"}}`\n",
       "\n",
       "---\n",
       "\n",
       "**Analysis & Insights:**\n",
       "\n",
       "Once the data is populated, we would perform the following analysis:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Category-wise Sales Volume\n",
       "\n",
       "**Analysis:**\n",
       "We would sum the total sales volume across all product categories to get an overall picture of transactional activity. Then, we would break down the units sold by each category.\n",
       "\n",
       "**Expected Insights:**\n",
       "*   **High Volume Categories:** Identify which categories move the most units. This indicates products with high transactional frequency or broad appeal. (e.g., if `Food & Beverage` has the highest volume, it suggests many small, frequent purchases).\n",
       "*   **Low Volume Categories:** Pinpoint categories with fewer unit sales. These might be niche products, higher-priced items, or items with longer purchase cycles.\n",
       "*   **Volume Distribution:** Understand if sales volume is concentrated in a few categories or evenly distributed across many.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Category-wise Revenue\n",
       "\n",
       "**Analysis:**\n",
       "We would display the total revenue generated from each product category over the past month, allowing for a clear understanding of the monetary contribution of each segment.\n",
       "\n",
       "**Expected Insights:**\n",
       "*   **Revenue Drivers:** Clearly identify the \"cash cow\" categories that bring in the most money. (e.g., if `Electronics` has the highest revenue, it's a key financial pillar).\n",
       "*   **Revenue vs. Volume Discrepancy:**\n",
       "    *   **High Revenue, Moderate/Low Volume:** This suggests high-value or high-margin products (e.g., `Electronics` might have lower volume than `Food & Beverage` but significantly higher revenue). These are often critical for profitability.\n",
       "    *   **High Volume, Moderate/Low Revenue:** Indicates commodity-like products or items with lower price points/margins (e.g., `Food & Beverage` might have high volume but lower total revenue compared to `Electronics`). These contribute to customer traffic and basket size.\n",
       "*   **Profitability Potential:** Revenue figures are crucial for assessing the financial health and potential of each category.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Category-wise Performance (Sales, Revenue, Customer Demand)\n",
       "\n",
       "**Analysis:**\n",
       "This section would combine the volume and revenue data with specific performance metrics related to customer demand and growth trends.\n",
       "\n",
       "**Expected Insights:**\n",
       "\n",
       "*   **Best Performing Categories:**\n",
       "    *   **Definition:** These categories would show a strong positive correlation across high sales volume, high revenue, and robust customer demand.\n",
       "    *   **Characteristics:**\n",
       "        *   **High Sales/Revenue Growth:** Consistently increasing unit sales and monetary value month-over-month.\n",
       "        *   **Strong Customer Demand:** Indicated by high search interest, good conversion rates, positive customer reviews, low return rates, and potentially high repeat purchase rates.\n",
       "    *   **Example:** If `Electronics` shows high revenue, steady sales growth, and a high \"Customer Demand Score\" (reflecting strong interest and satisfaction), it would be a top performer.\n",
       "\n",
       "*   **Underperforming Categories:**\n",
       "    *   **Definition:** Categories with stagnant or declining sales volume, low revenue contribution, and/or waning customer interest.\n",
       "    *   **Characteristics:**\n",
       "        *   Low or negative sales/revenue growth.\n",
       "        *   Low customer engagement, poor reviews, high return rates, or declining search trends.\n",
       "    *   **Example:** If `Books` have low volume, low revenue, and \"Customer Demand Score\" indicating declining interest, it would be an underperformer.\n",
       "\n",
       "*   **Emerging or Niche Performers:**\n",
       "    *   **Definition:** Categories that might not be top in absolute volume or revenue yet but show significant positive trends in growth or demand.\n",
       "    *   **Characteristics:** Rapid month-over-month growth in sales/revenue, sudden spikes in customer interest or searches, positive early feedback.\n",
       "    *   **Example:** A new category like \"Sustainable Living\" might have lower absolute numbers but show a \"200% MoM growth\" in demand and sales, marking it as an emerging opportunity.\n",
       "\n",
       "---\n",
       "\n",
       "**Overall Insights & Key Takeaways (Upon Data Provision):**\n",
       "\n",
       "Once the actual data is provided, the combined analysis would allow us to:\n",
       "\n",
       "1.  **Identify Core Business Drivers:** Pinpoint the 2-3 categories that are the absolute backbone of your sales and revenue.\n",
       "2.  **Uncover Hidden Gems:** Discover categories that, despite lower volume, yield high revenue (high-margin products).\n",
       "3.  **Spot Areas for Improvement:** Clearly see which categories are lagging and require intervention (e.g., marketing boost, pricing adjustment, product line review, inventory reduction).\n",
       "4.  **Understand Customer Preferences:** Gain a clearer picture of where genuine customer interest and purchasing power lie.\n",
       "5.  **Inform Strategic Decisions:** Guide decisions on inventory management, marketing budget allocation, product development, and resource deployment across categories.\n",
       "\n",
       "---\n",
       "\n",
       "**To get specific, actionable insights, please provide your sales, revenue, and performance data for each category.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Category Distribution: This section analyzes the distribution of sales across categories\n",
    "category_distribution = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate insights on the distribution of sales across categories based on the following:\n",
    "\n",
    "1. **Category-wise Sales Volume**: Summarize the total sales volume across all product categories.\n",
    "2. **Category-wise Revenue**: Display the total revenue generated from each product category over the past month.\n",
    "3. **Category-wise Performance**: Provide insights on which product categories are performing the best in terms of sales, revenue, and customer demand.\n",
    "\n",
    "Data:\n",
    "- Sales Volume by Category: {sales_volume_by_category_data}\n",
    "- Revenue by Category: {revenue_by_category_data}\n",
    "- Product Category Performance: {category_performance_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(category_distribution.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Usage Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To generate a comprehensive product usage forecast, I first need to define and simulate the `historical_sales_data`, `usage_probabilities`, `seasonal_sales_patterns_data`, and `current_inventory_data` as these were provided as placeholders.\n",
       "\n",
       "**Disclaimer:** The following forecast is based on *simulated data* and a simplified forecasting methodology. For real-world applications, actual granular data and more sophisticated time-series analysis (e.g., ARIMA, Prophet, exponential smoothing) would be required.\n",
       "\n",
       "---\n",
       "\n",
       "### Executive Summary\n",
       "\n",
       "This report provides a product usage forecast for the upcoming quarter (Q1 2024), covering sales predictions, overall demand, and recommended stock levels. Based on simulated historical data, Product A is expected to maintain its lead in sales and demand, followed by Product B and Product C, which shows significant growth potential but lower individual usage probability. Strategic ordering is recommended to ensure optimal stock levels and avoid both stockouts and excessive inventory.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Simulated Data Used for Forecast\n",
       "\n",
       "To demonstrate the methodology, I've created plausible data sets:\n",
       "\n",
       "**A. Historical Sales Data (Monthly for 2023)**\n",
       "\n",
       "| Month | Product A (Units) | Product B (Units) | Product C (Units) |\n",
       "| :---- | :------------------ | :------------------ | :------------------ |\n",
       "| Jan-23 | 95                  | 48                  | 18                  |\n",
       "| Feb-23 | 98                  | 47                  | 19                  |\n",
       "| Mar-23 | 102                 | 50                  | 22                  |\n",
       "| Apr-23 | 105                 | 52                  | 23                  |\n",
       "| May-23 | 108                 | 51                  | 24                  |\n",
       "| Jun-23 | 110                 | 53                  | 26                  |\n",
       "| Jul-23 | 107                 | 50                  | 25                  |\n",
       "| Aug-23 | 106                 | 49                  | 24                  |\n",
       "| Sep-23 | 103                 | 48                  | 22                  |\n",
       "| Oct-23 | 112                 | 54                  | 27                  |\n",
       "| Nov-23 | 115                 | 55                  | 28                  |\n",
       "| Dec-23 | 118                 | 56                  | 30                  |\n",
       "\n",
       "**B. Product Usage Probabilities**\n",
       "*(Interpretation: The probability that a sold unit of a product will be actively used or consumed within the forecast period.)*\n",
       "\n",
       "*   **Product A:** 0.95 (95% of sold units are typically used)\n",
       "*   **Product B:** 0.85 (85% of sold units are typically used)\n",
       "*   **Product C:** 0.70 (70% of sold units are typically used)\n",
       "\n",
       "**C. Seasonal Sales Patterns Data (Quarterly Multipliers)**\n",
       "*(Based on general observation, Q1 is often slower, Q2/Q3 stable, Q4 peak.)*\n",
       "\n",
       "*   **Q1 (Jan-Mar):** 0.90 (10% lower than average)\n",
       "*   **Q2 (Apr-Jun):** 1.05 (5% higher than average)\n",
       "*   **Q3 (Jul-Sep):** 1.00 (Average)\n",
       "*   **Q4 (Oct-Dec):** 1.15 (15% higher than average)\n",
       "\n",
       "**D. Current Stock Levels (As of End of Dec 2023)**\n",
       "\n",
       "*   **Product A:** 200 units\n",
       "*   **Product B:** 100 units\n",
       "*   **Product C:** 50 units\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Assumptions for Forecasting\n",
       "\n",
       "*   **Forecasting Period:** Q1 2024 (January, February, March)\n",
       "*   **Forecasting Method:**\n",
       "    *   **Base Sales:** Average monthly sales from the preceding year (2023) are used as a baseline.\n",
       "    *   **Trend:** A conservative overall growth trend of **+5%** year-over-year (applied to the quarterly average) is assumed for all products, reflecting general market expansion or internal initiatives.\n",
       "    *   **Seasonality:** The predefined quarterly multipliers are applied to adjust for seasonal fluctuations.\n",
       "*   **Safety Stock:** A **15% safety stock** buffer is added to the forecasted demand to mitigate against unforeseen demand spikes or supply chain delays.\n",
       "*   **Lead Time:** Assumed to be short enough that stock can be acquired to meet the Q1 demand by the start of the period.\n",
       "*   **Usage Probability Interpretation:** Directly applied as a multiplier to the sales forecast to derive effective usage demand.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Forecasting Methodology & Calculations\n",
       "\n",
       "#### Step 1: Calculate Average Monthly/Quarterly Historical Sales (2023)\n",
       "\n",
       "*   **Product A:** Sum = 1279 units. Average Monthly = 1279 / 12 = 106.58 units. Average Quarterly = 106.58 * 3 = **319.75 units.**\n",
       "*   **Product B:** Sum = 603 units. Average Monthly = 603 / 12 = 50.25 units. Average Quarterly = 50.25 * 3 = **150.75 units.**\n",
       "*   **Product C:** Sum = 288 units. Average Monthly = 288 / 12 = 24.00 units. Average Quarterly = 24.00 * 3 = **72.00 units.**\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Sales Forecast by Product (Q1 2024)\n",
       "\n",
       "**Formula:** `(Average Quarterly Sales 2023) * (1 + Annual Growth Trend) * Seasonal Multiplier (Q1)`\n",
       "\n",
       "*   **Product A:**\n",
       "    *   319.75 * (1 + 0.05) * 0.90\n",
       "    *   319.75 * 1.05 * 0.90 = **302.16 units ≈ 302 units**\n",
       "*   **Product B:**\n",
       "    *   150.75 * (1 + 0.05) * 0.90\n",
       "    *   150.75 * 1.05 * 0.90 = **142.46 units ≈ 142 units**\n",
       "*   **Product C:**\n",
       "    *   72.00 * (1 + 0.05) * 0.90\n",
       "    *   72.00 * 1.05 * 0.90 = **68.04 units ≈ 68 units**\n",
       "\n",
       "**Sales Forecast Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Sales (Units) |\n",
       "| :-------- | :----------------------- |\n",
       "| Product A | 302                      |\n",
       "| Product B | 142                      |\n",
       "| Product C | 68                       |\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Demand Forecast (Q1 2024)\n",
       "\n",
       "**Formula:** `Sales Forecast * Product Usage Probability`\n",
       "\n",
       "*   **Product A:**\n",
       "    *   302 units (Sales Forecast) * 0.95 (Usage Probability) = **286.9 units ≈ 287 units**\n",
       "*   **Product B:**\n",
       "    *   142 units (Sales Forecast) * 0.85 (Usage Probability) = **120.7 units ≈ 121 units**\n",
       "*   **Product C:**\n",
       "    *   68 units (Sales Forecast) * 0.70 (Usage Probability) = **47.6 units ≈ 48 units**\n",
       "\n",
       "**Demand Forecast Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Demand (Units) |\n",
       "| :-------- | :------------------------ |\n",
       "| Product A | 287                       |\n",
       "| Product B | 121                       |\n",
       "| Product C | 48                        |\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Future Stock Levels (Required to meet Q1 2024 Demand)\n",
       "\n",
       "**Formulas:**\n",
       "*   `Safety Stock = Forecasted Demand * 0.15`\n",
       "*   `Required Stock Level = Forecasted Demand + Safety Stock`\n",
       "*   `Units to Order = Required Stock Level - Current Stock Level` (If positive, order; if zero or negative, no order needed, or potentially surplus to manage).\n",
       "\n",
       "*Self-correction: The \"Future Stock Levels\" typically refers to the *target* stock level to have at the *start* of the period to cover the period's demand. The \"Units to Order\" is the action needed.*\n",
       "\n",
       "**A. Product A:**\n",
       "*   Demand: 287 units\n",
       "*   Safety Stock: 287 * 0.15 = 43.05 units ≈ 43 units\n",
       "*   **Required Stock Level (Target):** 287 + 43 = **330 units**\n",
       "*   Current Stock: 200 units\n",
       "*   **Units to Order:** 330 - 200 = **130 units**\n",
       "\n",
       "**B. Product B:**\n",
       "*   Demand: 121 units\n",
       "*   Safety Stock: 121 * 0.15 = 18.15 units ≈ 18 units\n",
       "*   **Required Stock Level (Target):** 121 + 18 = **139 units**\n",
       "*   Current Stock: 100 units\n",
       "*   **Units to Order:** 139 - 100 = **39 units**\n",
       "\n",
       "**C. Product C:**\n",
       "*   Demand: 48 units\n",
       "*   Safety Stock: 48 * 0.15 = 7.2 units ≈ 7 units\n",
       "*   **Required Stock Level (Target):** 48 + 7 = **55 units**\n",
       "*   Current Stock: 50 units\n",
       "*   **Units to Order:** 55 - 50 = **5 units**\n",
       "\n",
       "**Future Stock Levels & Ordering Summary (Q1 2024)**\n",
       "\n",
       "| Product   | Forecasted Demand (Units) | Safety Stock (Units) | Required Stock Level (Target) | Current Stock (Units) | Units to Order (Approx.) |\n",
       "| :-------- | :------------------------ | :------------------- | :---------------------------- | :-------------------- | :----------------------- |\n",
       "| Product A | 287                       | 43                   | 330                           | 200                   | 130                      |\n",
       "| Product B | 121                       | 18                   | 139                           | 100                   | 39                       |\n",
       "| Product C | 48                        | 7                    | 55                            | 50                    | 5                        |\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Recommendations and Next Steps\n",
       "\n",
       "1.  **Prioritize Product A:** It continues to be the highest demand product. Ensure its supply chain is robust to meet the forecasted 130 units needed for Q1.\n",
       "2.  **Monitor Product C:** While its forecasted sales and demand are lower, it has a lower usage probability (0.70), suggesting some units sold might not translate to immediate active use. The current stock is nearly sufficient, but 5 units are still needed. Its historical data shows strong growth, so continued monitoring for a higher growth trend in future forecasts might be warranted.\n",
       "3.  **Review Safety Stock Levels:** The 15% safety stock is a general assumption. For critical products or those with high demand variability or long lead times, a more dynamic safety stock calculation (e.g., based on forecast error and lead time variability) would be beneficial.\n",
       "4.  **Refine Forecasting Model:** For more accuracy, consider:\n",
       "    *   **More Granular Data:** Weekly or daily sales data can capture short-term trends.\n",
       "    *   **Advanced Models:** Time series analysis methods (ARIMA, Exponential Smoothing, Prophet) can better capture complex trends, seasonality, and cycles.\n",
       "    *   **External Factors:** Incorporate market trends, marketing campaigns, competitor activities, economic indicators, and holiday effects.\n",
       "    *   **Product Lifecycle:** Account for new product introductions, mature products, and products nearing end-of-life.\n",
       "5.  **Iterate and Adjust:** Forecasting is an ongoing process. Regularly review actual sales and demand against forecasts and adjust the model parameters accordingly for improved accuracy in subsequent periods.\n",
       "\n",
       "This structured forecast provides a solid basis for operational planning for Q1 2024."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Product Usage Forecast: This section forecasts the future usage of products based on historical sales\n",
    "product_usage_forecast = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate a product usage forecast for the upcoming period based on historical data and trends:\n",
    "\n",
    "1. **Sales Forecast by Product**: Predict the sales volume for each product in the next quarter/year.\n",
    "2. **Demand Forecast**: Provide a demand forecast for products based on historical sales, usage probabilities, and seasonal patterns.\n",
    "3. **Future Stock Levels**: Estimate the required stock levels for each product to meet forecasted demand.\n",
    "\n",
    "Data:\n",
    "- Historical Sales Data: {historical_sales_data}\n",
    "- Product Usage Data: {usage_probabilities}\n",
    "- Seasonal Patterns: {seasonal_sales_patterns_data}\n",
    "- Current Stock Levels: {current_inventory_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_usage_forecast.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\pickle.py:1760: UserWarning: [18:43:14] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\gbm\\../common/error_msg.h:82: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Sales Data\n",
    "sales_data = orderData\n",
    "\n",
    "# Sales Predictions\n",
    "current_date = datetime.now()\n",
    "next_month_date = current_date + relativedelta(months=1)\n",
    "next_month_yearmonth = next_month_date.strftime(\"%Y-%m\")\n",
    "\n",
    "sales_pred_input = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "sales_predictions = []\n",
    "\n",
    "for index, row in sales_pred_input.iterrows():\n",
    "    sales_predictions.append({\n",
    "        'Category Name': row.Category,\n",
    "        'Customer Segment': row.CustomerSegment,\n",
    "        'Predicted Demand for next month': s.predict_demand_forecast({\n",
    "            'category': row.Category,\n",
    "            'month': next_month_yearmonth,\n",
    "            'avg_price': row.AveragePrice,\n",
    "            'customer_segment': row.CustomerSegment,\n",
    "            'discount_rate': row.AverageDiscount\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "# Product Categories\n",
    "product_categories = [\"Clothing\",\"Technology\",\"Sports and Fitness\",\"Other\"]\n",
    "\n",
    "# Current Inventory\n",
    "current_inventory = inventoryData\n",
    "\n",
    "# Usage Probabilities\n",
    "usage_probabilities = \"Currently empty. Please ignore this section for now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Insights Section\n",
    "section_sales_insights = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate a sales insights report that describes information for the following areas:\n",
    "\n",
    "1. Sales Trends: Summarize sales based on the provided data. Provide insights on which product categories are seeing the highest demand.\n",
    "2. Product Performance: Analyze the best-selling product categories by quantity. Highlight the top 3 performing categories.\n",
    "3. Product Demand Forecast: Based on the historical sales and usage probability, forecast the demand for the next month.\n",
    "4. Restocking or Discontinuation: Recommend which products should be restocked and which should be discontinued, based on sales trends and inventory levels.\n",
    "\n",
    "Data:\n",
    "- Historical sales data: {sales_data}\n",
    "- Sales volume predictions for next month: {sales_predictions}\n",
    "- Product categories: {product_categories}\n",
    "- Current inventory levels: {current_inventory}\n",
    "- Usage probabilities: {usage_probabilities}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_sales_insights.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "location_predictions = []\n",
    "for item in inventoryData:\n",
    "    location_predictions.append({\n",
    "        'Item Id': item['ItemId'],\n",
    "        'Current Location': item['Location'],\n",
    "        'Predicted Location': s.predict_location({\n",
    "            'Priority': item['Priority'],\n",
    "            'Product_Type': item['Category'],\n",
    "            'Size': item['Size'],\n",
    "            'Order_Quantity': item['Quantity'],\n",
    "            'Weight': item['Weight']\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "section_storage_optimizations = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Provide detailed storage optimization recommendations based on:\n",
    "\n",
    "1. Current storage utilization metrics\n",
    "2. Model-predicted optimal locations vs current locations\n",
    "3. List of items flagged for relocation, including:\n",
    "   - Current location\n",
    "   - Recommended location\n",
    "\n",
    "Data:\n",
    "{inventoryData}\n",
    "{location_predictions}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_storage_optimizations.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "section_anomalies_detected = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate an anomalies section that lists all detected storage anomalies detected in a table. Include each item's current location, predicted location, item id, and name.\n",
    "Include the reason for each anomaly.\n",
    "\n",
    "Data:\n",
    "{s.detect_anomalies(inventoryData)}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_anomalies_detected.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Markdown content\n",
    "monthly_report = f'''<h1 style=\"text-align:center;\">Monthly Report</h1><br>\n",
    "\n",
    "# Products Overview:\n",
    "section_products_overview.text\n",
    "\n",
    "# Category Distribution:\n",
    "section_category_distribution.text\n",
    "\n",
    "# Product Usage Forecast:\n",
    "section_product_usage.text\n",
    "\n",
    "# Sales Insights:\n",
    "{section_sales_insights.text}\n",
    "\n",
    "# Storage Optimizations:\n",
    "{section_storage_optimizations.text}\n",
    "\n",
    "# Anomalies Detected:\n",
    "{section_anomalies_detected.text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_summary = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Provide a brief and concise summary of the provided report, covering all the key points highlighted by each section. Highlight the important information for each section in a bullet list, with the final paragraph providing general insight on overall performance.\n",
    "\n",
    "Report:\n",
    "{monthly_report}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display(Markdown(section_summary.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now()\n",
    "monthly_report = f\"\"\"# <h1 style=\"text-align:center;\">Monthly Report ({current_date.date()})</h1><br>\n",
    "\n",
    "# Products Overview:\n",
    "section_products_overview.text\n",
    "\n",
    "# Category Distribution:\n",
    "section_category_distribution.text\n",
    "\n",
    "# Product Usage Forecast:\n",
    "section_product_usage.text\n",
    "\n",
    "# Sales Insights:\n",
    "{section_sales_insights.text}\n",
    "\n",
    "# Storage Optimizations:\n",
    "{section_storage_optimizations.text}\n",
    "\n",
    "# Anomalies Detected:\n",
    "{section_anomalies_detected.text}\n",
    "\n",
    "# Summary:\n",
    "{section_summary.text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown_pdf import MarkdownPdf, Section\n",
    "\n",
    "pdf = MarkdownPdf(toc_level=1)\n",
    "pdf.add_section(Section(monthly_report)) # Add Section(md_content, user_css=css_content) for custom CSS\n",
    "pdf.save(f\"MonthlyReport_({current_date.date()}).pdf\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompting.ipynb",
   "toc_visible": true
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "aap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
