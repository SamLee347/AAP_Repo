{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeadDkMiISin",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# AI Applications Project: Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0c13de5f68f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Importing the generative ai\n",
    "%pip install -U -q \"google-genai>=1.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4YDYyfRYN7L"
   },
   "source": [
    "### Setting up API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8K1RpmMfh20"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "GOOGLE_API_KEY = input(\"Enter your Google API key:\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ll79uwEK4uPJ"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 14:00:29,939 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2025-08-18 14:00:29,940 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 14:00:29,944 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2025-08-18 14:00:29,945 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 14:00:29,946 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2025-08-18 14:00:29,946 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-08-18 14:00:29,947 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-08-18 14:00:29,949 INFO sqlalchemy.engine.Engine SELECT `Inventory`.`ItemId` AS `Inventory_ItemId`, `Inventory`.`ItemName` AS `Inventory_ItemName`, `Inventory`.`ItemCategory` AS `Inventory_ItemCategory`, `Inventory`.`ItemQuantity` AS `Inventory_ItemQuantity`, `Inventory`.`UnitsSold` AS `Inventory_UnitsSold`, `Inventory`.`Weight` AS `Inventory_Weight`, `Inventory`.`Size` AS `Inventory_Size`, `Inventory`.`Priority` AS `Inventory_Priority`, `Inventory`.`Location` AS `Inventory_Location`, `Inventory`.`Date` AS `Inventory_Date`, `Inventory`.`Dispose` AS `Inventory_Dispose` \n",
      "FROM `Inventory`\n",
      "2025-08-18 14:00:29,949 INFO sqlalchemy.engine.Engine [generated in 0.00042s] {}\n",
      "2025-08-18 14:00:29,973 INFO sqlalchemy.engine.Engine SELECT `Order`.`OrderId` AS `Order_OrderId`, `Order`.`ItemId` AS `Order_ItemId`, `Order`.`OrderQuantity` AS `Order_OrderQuantity`, `Order`.`Sales` AS `Order_Sales`, `Order`.`Price` AS `Order_Price`, `Order`.`Discount` AS `Order_Discount`, `Order`.`Profit` AS `Order_Profit`, `Order`.`DateOrdered` AS `Order_DateOrdered`, `Order`.`DateReceived` AS `Order_DateReceived`, `Order`.`CustomerSegment` AS `Order_CustomerSegment` \n",
      "FROM `Order`\n",
      "2025-08-18 14:00:29,974 INFO sqlalchemy.engine.Engine [generated in 0.00068s] {}\n",
      "2025-08-18 14:00:29,975 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Database.db import SessionLocal\n",
    "from Database_Table import Inventory, Order\n",
    "\n",
    "def getDbContent():\n",
    "    session = SessionLocal()\n",
    "    inventory_records = session.query(Inventory).all()\n",
    "    order_records = session.query(Order).all()\n",
    "    session.close()\n",
    "    return inventory_records, order_records\n",
    "\n",
    "inventory, order = getDbContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbtoList(records):\n",
    "    output_list = []\n",
    "    for r in records:\n",
    "        if isinstance(r, Inventory):\n",
    "            data = {\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"ItemName\": r.ItemName,\n",
    "                \"Category\": r.ItemCategory,\n",
    "                \"Quantity\": r.ItemQuantity, \n",
    "                \"UnitsSold\": r.UnitsSold,\n",
    "                \"Weight\": r.Weight, \n",
    "                \"Size\": r.Size,\n",
    "                \"Priority\": r.Priority, \n",
    "                \"Location\": r.Location,\n",
    "                \"Date\": r.Date, \n",
    "                \"Dispose\": r.Dispose                \n",
    "            }\n",
    "        elif isinstance(r, Order):\n",
    "            data = {\n",
    "                \"OrderId\": r.OrderId,\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"OrderQuantity\": r.OrderQuantity, \n",
    "                \"Sales\": r.Sales, \n",
    "                \"Price\": r.Price, \n",
    "                \"Discount\": r.Discount,\n",
    "                \"Profit\": r.Profit, \n",
    "                \"DateOrdered\": r.DateOrdered,\n",
    "                \"DateReceived\": r.DateReceived,\n",
    "                \"CustomerSegment\": r.CustomerSegment\n",
    "            }\n",
    "        else:\n",
    "            continue\n",
    "        output_list.append(data)\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "inventoryData = dbtoList(inventory)\n",
    "orderData = dbtoList(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown\n",
    "\n",
    "class Supervised_Models:\n",
    "    # Location Prediction Model\n",
    "    def predict_location(input_data):\n",
    "        with open('../../Supervised models/Samuel/storage_prediction_model.pkl', 'rb') as file:\n",
    "            storage_prediction_model = pickle.load(file)\n",
    "            \n",
    "        categorical_features = {\n",
    "            'Priority': ['High','Low','Medium'],\n",
    "            'Product_Type': ['Clothing','Technology','Other','Sports and Fitness'],\n",
    "            'Size': ['Large','Medium','Small']\n",
    "        }\n",
    "        numerical_features = ['Order_Quantity', 'Weight']\n",
    "        one_hot_columns = []\n",
    "        \n",
    "        for feature, values in categorical_features.items():\n",
    "            for value in values:\n",
    "                one_hot_columns.append(f\"{feature}_{value}\")\n",
    "            \n",
    "        # Combine with numerical features to get all feature names\n",
    "        all_feature_names = one_hot_columns + numerical_features\n",
    "\n",
    "        features_dict = {col: 0 for col in all_feature_names}\n",
    "    \n",
    "        # Set one-hot encoded features\n",
    "        for feature, values in categorical_features.items():\n",
    "            if feature in input_data:\n",
    "                selected_value = input_data[feature]\n",
    "                one_hot_col = f\"{feature}_{selected_value}\"\n",
    "                if one_hot_col in features_dict:\n",
    "                    features_dict[one_hot_col] = 1\n",
    "    \n",
    "        # Set numerical features\n",
    "        for feature in numerical_features:\n",
    "            if feature in input_data:\n",
    "                features_dict[feature] = float(input_data[feature])\n",
    "        \n",
    "        # Convert to array in the correct order\n",
    "        features_array = np.array([features_dict[col] for col in all_feature_names]).reshape(1, -1)\n",
    "\n",
    "        prediction = storage_prediction_model.predict(features_array)\n",
    "        return prediction\n",
    "\n",
    "    def demand_forecast_preprocessor(order_data, inventory_data):\n",
    "        # Create Dataframe\n",
    "        order = pd.DataFrame(order_data)\n",
    "        inventory = pd.DataFrame(inventory_data)\n",
    "\n",
    "        # Ensure dates are in datetime format\n",
    "        order['DateOrdered'] = pd.to_datetime(order['DateOrdered'])\n",
    "        \n",
    "        # Extract Month (period or string, depending on preference)\n",
    "        order['OrderMonth'] = order['DateOrdered'].dt.to_period('M')\n",
    "        \n",
    "        # Merge with Category lookup table\n",
    "        merged_df = order.merge(inventory, on='ItemId', how='left')\n",
    "        \n",
    "        # Group and aggregate\n",
    "        result_df = (\n",
    "            merged_df\n",
    "            .groupby(['OrderMonth', 'Category', 'CustomerSegment'], as_index=False)\n",
    "            .agg(\n",
    "                AveragePrice=('Price', 'mean'),\n",
    "                AverageDiscount=('Discount', 'mean')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    # Demand forecast model\n",
    "    def predict_demand_forecast(input_data):\n",
    "        demand_forecast_model = joblib.load('../../Supervised models/ShernFai/model/salesforecast(categories).pkl')\n",
    "        with open('../../Supervised models/ShernFai/model/salesforecast_preprocessor.pkl', 'rb') as f:\n",
    "            preprocessor_data = pickle.load(f)\n",
    "\n",
    "        categories = {\n",
    "            \"Clothing\" : [\n",
    "                \"Cleats\",\n",
    "                \"Men's Footwear\",\n",
    "                \"Women's Apparel\"\n",
    "            ],\n",
    "            \"Technology\": [\n",
    "                \"Electronics\",\n",
    "                \"Video Games\",\n",
    "                \"Cameras\",\n",
    "                \"Computers\",\n",
    "            ],\n",
    "            \"Sports and Fitness\": [\n",
    "                \"Cardio Equipment\",\n",
    "                \"Indoor/Outdoor Games\",\n",
    "                \"Water Sports\",\n",
    "                \"Shop By Sport\",\n",
    "                \"Camping & Hiking\",\n",
    "                \"Fishing\"\n",
    "            ],\n",
    "            \"Other\": [\n",
    "                \"Garden\",\n",
    "                \"Pet Supplies\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        cat_keys = list(categories.keys())\n",
    "\n",
    "        # Extract preprocessor components\n",
    "        le_category = preprocessor_data['label_encoder_category']\n",
    "        reference_date = preprocessor_data['reference_date']\n",
    "        unique_categories = preprocessor_data['unique_categories']\n",
    "        feature_columns = preprocessor_data['feature_columns']\n",
    "\n",
    "        # Get data\n",
    "        category_name = input_data['category']\n",
    "        future_month = input_data['month']\n",
    "        avg_price = float(input_data['avg_price'])\n",
    "        customer_segment = input_data['customer_segment']\n",
    "        discount_rate = float(input_data['discount_rate'])\n",
    "        \n",
    "        # Parse the future date\n",
    "        future_date = pd.to_datetime(future_month)\n",
    "        \n",
    "        # Calculate time features for the future date\n",
    "        months_since_start = ((future_date - reference_date).days / 30.44)\n",
    "        \n",
    "        # Create test data with numerical time features\n",
    "        test_data = {\n",
    "            'Category Name': category_name,\n",
    "            'Average Product Price': avg_price,\n",
    "            'Customer Segment': customer_segment,\n",
    "            'Order Item Discount Rate': discount_rate,\n",
    "            # Time features (numerical - can handle ANY future date!)\n",
    "            'Year': future_date.year,\n",
    "            'Month': future_date.month,\n",
    "            'Quarter': future_date.quarter,\n",
    "            'Months_Since_Start': int(months_since_start),\n",
    "            'Month_Sin': np.sin(2 * np.pi * future_date.month / 12),\n",
    "            'Month_Cos': np.cos(2 * np.pi * future_date.month / 12),\n",
    "            'Year_Trend': future_date.year - reference_date.year\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        test_df = pd.DataFrame([test_data])\n",
    "        \n",
    "        # Handle unknown category\n",
    "        if category_name not in cat_keys:\n",
    "            print(f\"Unknown category '{category_name}' - using default: {cat_keys[0]}\")\n",
    "            test_df['Category Name'] = cat_keys[0]\n",
    "            category_name = cat_keys[0]\n",
    "        \n",
    "        # One-hot encode customer segment\n",
    "        test_df = pd.get_dummies(test_df, columns=['Customer Segment'], drop_first=True)\n",
    "        \n",
    "        # Ensure same columns as training (crucial!)\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        total = 0\n",
    "        num = len(categories[category_name])\n",
    "        for subclass in categories[category_name]:\n",
    "            test_df['Category Name'] = subclass\n",
    "            test_df['Category Name'] = le_category.transform(test_df['Category Name'])\n",
    "            total += demand_forecast_model.predict(test_df)\n",
    "        \n",
    "        avg_demand = total / num\n",
    "        \n",
    "        return avg_demand\n",
    "\n",
    "    def detect_anomalies(inventory_list):\n",
    "        anomalies_detected = []\n",
    "        for item in inventory_list:\n",
    "            current_location = item['Location']\n",
    "            predicted_location = Supervised_Models.predict_location({\n",
    "                \"Priority\": item['Priority'],\n",
    "                \"Product_Type\": item['Category'],\n",
    "                \"Size\": item['Size'],\n",
    "                \"Order_Quantity\": item['Quantity'],\n",
    "                \"Weight\": item['Weight']\n",
    "            })[0]\n",
    "\n",
    "            #print(f\"\\nCurrent Location: {current_location}\")\n",
    "            #print(f\"Predicted Location: {predicted_location}\")\n",
    "            if current_location != predicted_location:\n",
    "                #print(f\"Anomaly detected! Item id:{item['ItemId']} is stored at location {current_location} while it should be stored at {predicted_location}.\")\n",
    "                anomalies_detected.append({'ItemId': item['ItemId'], 'ItemName': item['ItemName'], 'CurrentLocation': current_location, 'PredictedLocation': predicted_location})\n",
    "\n",
    "        return anomalies_detected\n",
    "\n",
    "s = Supervised_Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "print(s.predict_location({\n",
    "    \"Priority\": \"Medium\",\n",
    "    \"Product_Type\": \"Sports and Fitness\",\n",
    "    \"Size\": \"Medium\",\n",
    "    \"Order_Quantity\": 12,\n",
    "    \"Weight\": 10.78\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.detect_anomalies(inventoryData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(s.predict_demand_forecast({\n",
    "    'category': \"Clothing\",\n",
    "    'month': \"2025-05\",\n",
    "    'avg_price': 10.0,\n",
    "    'customer_segment': \"Consumer\",\n",
    "    'discount_rate': 0.12\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Products Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Overview: This section summarizes the overall performance of products\n",
    "product_overview = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate an overview of products based on the following:\n",
    "\n",
    "1. **Top Products**: Identify the top-selling products by sales volume and revenue over the past month.\n",
    "2. **Product Performance**: Analyze the performance of each product category in terms of sales, demand, and revenue.\n",
    "3. **Sales by Product**: Present a summary of sales for each product, including revenue, volume sold, and average price.\n",
    "\n",
    "Data:\n",
    "- Sales Data: {sales_data}\n",
    "- Product Categories: {product_categories_data}\n",
    "- Product Sales Volume: {sales_volume_data}\n",
    "- Product Revenue: {product_revenue_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_overview.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Distribution: This section analyzes the distribution of sales across categories\n",
    "category_distribution = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate insights on the distribution of sales across categories based on the following:\n",
    "\n",
    "1. **Category-wise Sales Volume**: Summarize the total sales volume across all product categories.\n",
    "2. **Category-wise Revenue**: Display the total revenue generated from each product category over the past month.\n",
    "3. **Category-wise Performance**: Provide insights on which product categories are performing the best in terms of sales, revenue, and customer demand.\n",
    "\n",
    "Data:\n",
    "- Sales Volume by Category: {sales_volume_by_category_data}\n",
    "- Revenue by Category: {revenue_by_category_data}\n",
    "- Product Category Performance: {category_performance_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(category_distribution.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Product Usage Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Usage Forecast: This section forecasts the future usage of products based on historical sales\n",
    "product_usage_forecast = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='''\n",
    "Generate a product usage forecast for the upcoming period based on historical data and trends:\n",
    "\n",
    "1. **Sales Forecast by Product**: Predict the sales volume for each product in the next quarter/year.\n",
    "2. **Demand Forecast**: Provide a demand forecast for products based on historical sales, usage probabilities, and seasonal patterns.\n",
    "3. **Future Stock Levels**: Estimate the required stock levels for each product to meet forecasted demand.\n",
    "\n",
    "Data:\n",
    "- Historical Sales Data: {historical_sales_data}\n",
    "- Product Usage Data: {usage_probabilities}\n",
    "- Seasonal Patterns: {seasonal_sales_patterns_data}\n",
    "- Current Stock Levels: {current_inventory_data}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(product_usage_forecast.text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Sales Data\n",
    "sales_data = orderData\n",
    "\n",
    "# Sales Predictions\n",
    "current_date = datetime.now()\n",
    "next_month_date = current_date + relativedelta(months=1)\n",
    "next_month_yearmonth = next_month_date.strftime(\"%Y-%m\")\n",
    "\n",
    "sales_pred_input = s.demand_forecast_preprocessor(orderData, inventoryData)\n",
    "sales_predictions = []\n",
    "\n",
    "for index, row in sales_pred_input.iterrows():\n",
    "    sales_predictions.append({\n",
    "        'Category Name': row.Category,\n",
    "        'Customer Segment': row.CustomerSegment,\n",
    "        'Predicted Demand for next month': s.predict_demand_forecast({\n",
    "            'category': row.Category,\n",
    "            'month': next_month_yearmonth,\n",
    "            'avg_price': row.AveragePrice,\n",
    "            'customer_segment': row.CustomerSegment,\n",
    "            'discount_rate': row.AverageDiscount\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "# Product Categories\n",
    "product_categories = [\"Clothing\",\"Technology\",\"Sports and Fitness\",\"Other\"]\n",
    "\n",
    "# Current Inventory\n",
    "current_inventory = inventoryData\n",
    "\n",
    "# Usage Probabilities\n",
    "usage_probabilities = \"Currently empty. Please ignore this section for now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Sales Insights Report: June - July 2025 Performance & Future Outlook\n",
       "\n",
       "This report provides a comprehensive analysis of sales performance for June and July 2025, offering insights into sales trends, product performance, demand forecasts, and recommendations for inventory management.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Sales Trends\n",
       "\n",
       "**Overall Sales Summary:**\n",
       "Based on the provided historical data for June and July 2025, the total sales amounted to **$90,000** across 12 orders, with a total of **900 units** sold.\n",
       "\n",
       "**Product Category Demand:**\n",
       "The sales data indicates demand across two primary product categories: 'Technology' and 'Other'.\n",
       "\n",
       "*   **Other Category:** This category is seeing the highest demand, generating **$60,000** in sales from **600 units** sold (e.g., Chairs). Sales for this category occurred consistently in July 2025.\n",
       "*   **Technology Category:** This category generated **$30,000** in sales from **300 units** sold (e.g., Laptops). Sales for this category occurred consistently in June 2025.\n",
       "\n",
       "**Insight:** While both categories contribute significantly, the 'Other' category currently holds a stronger position in terms of both total sales revenue and units sold within the recorded period.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Product Performance\n",
       "\n",
       "Analyzing the best-selling product categories by quantity sold further highlights the current market preferences.\n",
       "\n",
       "**Top Performing Categories (by Quantity Sold):**\n",
       "\n",
       "1.  **Other:** 600 units sold (e.g., Chairs)\n",
       "2.  **Technology:** 300 units sold (e.g., Laptops)\n",
       "\n",
       "**Insight:** The 'Other' category demonstrates superior performance in terms of sales volume, selling twice as many units as the 'Technology' category within the observed timeframe. Given only two active product categories in the sales data, these are the top two.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Product Demand Forecast (Next Month)\n",
       "\n",
       "Based on the provided sales volume predictions for the next month, here is the anticipated demand:\n",
       "\n",
       "*   **Technology Category (Corporate Segment):** Forecasted demand of **126.70 units**.\n",
       "*   **Other Category (Consumer Segment):** Forecasted demand of **128.16 units**.\n",
       "\n",
       "**Insight:** The forecast suggests a relatively balanced demand for both categories in the upcoming month, with slightly higher demand for the 'Other' category. It's important to note that these predictions are tied to specific customer segments (Corporate for Technology, Consumer for Other).\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Restocking or Discontinuation Recommendations\n",
       "\n",
       "To provide recommendations, we will compare historical sales, predicted demand, and current inventory levels.\n",
       "\n",
       "**Current Inventory Overview:**\n",
       "\n",
       "*   **Technology (Laptops - ItemId 1):**\n",
       "    *   Current Stock: 600 units (6 records x 100 units/record)\n",
       "    *   Historical Units Sold (June-July): 300 units\n",
       "    *   Predicted Demand (Next Month): ~127 units\n",
       "*   **Other (Chairs - ItemId 2):**\n",
       "    *   Current Stock: 1200 units (6 records x 200 units/record)\n",
       "    *   Historical Units Sold (June-July): 600 units\n",
       "    *   Predicted Demand (Next Month): ~128 units\n",
       "\n",
       "**Recommendations:**\n",
       "\n",
       "*   **Technology Category (Laptops):**\n",
       "    *   **Recommendation: No immediate restocking required.**\n",
       "    *   **Justification:** The current inventory of 600 units significantly exceeds both the historical sales volume (300 units over two months) and the predicted demand for the next month (~127 units). At the current sales rate, existing stock appears sufficient for at least 4-5 months, assuming consistent demand.\n",
       "*   **Other Category (Chairs):**\n",
       "    *   **Recommendation: No immediate restocking required.**\n",
       "    *   **Justification:** Similarly, the current inventory of 1200 units is well above both historical sales (600 units over two months) and the predicted demand for the next month (~128 units). This stock level should comfortably cover demand for an extended period.\n",
       "*   **Discontinuation:**\n",
       "    *   **Recommendation: No products should be discontinued at this time.**\n",
       "    *   **Justification:** Both 'Technology' and 'Other' categories are actively selling, showing consistent historical demand, and have positive demand forecasts for the next month. There are no indicators (e.g., zero sales, high inventory with no demand, or 'Dispose' flag being true) to suggest discontinuation for any listed item.\n",
       "\n",
       "---\n",
       "\n",
       "**Summary Conclusion:**\n",
       "\n",
       "The business is experiencing healthy demand for both its 'Technology' and 'Other' product categories, with 'Other' currently leading in sales volume. Inventory levels for both categories are robust, indicating no immediate need for restocking. Continuous monitoring of sales trends and demand forecasts is recommended to optimize inventory strategy and capitalize on market opportunities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sales Insights Section\n",
    "section_sales_insights = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate a sales insights report that describes information for the following areas:\n",
    "\n",
    "1. Sales Trends: Summarize sales based on the provided data. Provide insights on which product categories are seeing the highest demand.\n",
    "2. Product Performance: Analyze the best-selling product categories by quantity. Highlight the top 3 performing categories.\n",
    "3. Product Demand Forecast: Based on the historical sales and usage probability, forecast the demand for the next month.\n",
    "4. Restocking or Discontinuation: Recommend which products should be restocked and which should be discontinued, based on sales trends and inventory levels.\n",
    "\n",
    "Data:\n",
    "- Historical sales data: {sales_data}\n",
    "- Sales volume predictions for next month: {sales_predictions}\n",
    "- Product categories: {product_categories}\n",
    "- Current inventory levels: {current_inventory}\n",
    "- Usage probabilities: {usage_probabilities}'''\n",
    ")\n",
    "\n",
    "display(Markdown(section_sales_insights.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This report provides detailed storage optimization recommendations based on your provided inventory data and model-predicted optimal locations.\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "The analysis reveals that your current inventory is split between two primary locations, A-1 and B-2. The model strongly recommends consolidating all items from both A-1 and B-2 into a single location, B-5. This suggests B-5 is either a new, highly optimized, more central, or higher-capacity storage area designed for improved efficiency. The primary recommendation is a full-scale relocation of all current stock to B-5, followed by a strategic re-evaluation of locations A-1 and B-2.\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Current Storage Utilization Metrics\n",
       "\n",
       "Based on the provided inventory data, here's an overview of the current storage utilization:\n",
       "\n",
       "**Overall Inventory Snapshot:**\n",
       "\n",
       "*   **Total Unique Items:** 12\n",
       "*   **Total Quantity of Stock:** 1,800 units\n",
       "    *   900 units of 'Laptop' (or similar Technology items)\n",
       "    *   900 units of 'Chair' (or similar Other items)\n",
       "*   **Total Estimated Volume Occupied:** 27,000 cubic units (assuming 'Size' is in cubic units per item)\n",
       "*   **Total Estimated Weight:** 2,700 kg (assuming 'Weight' is per item)\n",
       "\n",
       "**Utilization by Current Location:**\n",
       "\n",
       "| Location | Item Category | Item Name (Examples) | Total Quantity | Total Volume (Est.) | Total Weight (Est.) |\n",
       "| :------- | :------------ | :------------------- | :------------- | :------------------ | :------------------ |\n",
       "| **A-1**  | Technology    | Laptop, Unknown Item | 900            | 9,000               | 1,350               |\n",
       "| **B-2**  | Other         | Chair, Unknown Item  | 900            | 18,000              | 1,350               |\n",
       "| **Total**|               |                      | **1,800**      | **27,000**          | **2,700**           |\n",
       "\n",
       "**Observations:**\n",
       "\n",
       "*   Locations A-1 and B-2 currently hold an equal number of total units (900 each) and total weight.\n",
       "*   Location B-2, however, holds twice the estimated volume due to the larger size of 'Chair' units (20.0 vs 10.0 for 'Laptop').\n",
       "*   Both 'Laptop' and 'Chair' items have a 50% turnover rate based on `UnitsSold / Quantity` (50/100 for Laptop, 100/200 for Chair), indicating they are relatively fast-moving items that benefit from accessible locations.\n",
       "*   Items 9 and 10 have `ItemName` as `None`. While their physical attributes are recorded, their lack of a descriptive name should be addressed for better inventory management.\n",
       "*   All items are marked `Dispose: False`, so no disposal recommendations are immediately required.\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Model-Predicted Optimal Locations vs. Current Locations\n",
       "\n",
       "The model's predictions are remarkably consistent and point towards a significant shift in your storage strategy.\n",
       "\n",
       "**Key Findings:**\n",
       "\n",
       "*   **Universal Recommendation for B-5:** For every single item (1 through 12), regardless of its current location (A-1 or B-2), the model recommends relocation to **B-5**.\n",
       "*   **Zero Retention in Current Locations:** The model does not suggest keeping any items in A-1 or B-2, indicating these locations are suboptimal for your current inventory strategy.\n",
       "\n",
       "**Interpretation & Implications:**\n",
       "\n",
       "This uniform recommendation strongly suggests that **B-5 is considered the most efficient or suitable storage location for all your current inventory.** Possible reasons for B-5's optimality include:\n",
       "\n",
       "*   **Strategic Consolidation:** B-5 might be a new central hub, closer to shipping/receiving, or optimized for faster picking and packing.\n",
       "*   **Increased Efficiency:** It could incorporate automation, better layout, or specialized storage solutions that reduce retrieval times and operational costs.\n",
       "*   **Capacity:** B-5 is presumed to have sufficient capacity to accommodate the entirety of your current inventory (1,800 units, 27,000 volume units).\n",
       "*   **Product Characteristics Alignment:** B-5 might be ideally suited for both high-priority (Laptop) and larger-volume (Chair) fast-moving items due to its design or accessibility.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. List of Items Flagged for Relocation\n",
       "\n",
       "Based on the model's recommendations, **all 12 items currently in stock are flagged for relocation.**\n",
       "\n",
       "| Item ID | Item Name     | Category   | Current Location | Recommended Location | Quantity | Priority | Units Sold (for context) |\n",
       "| :------ | :------------ | :--------- | :--------------- | :------------------- | :------- | :------- | :----------------------- |\n",
       "| 1       | Laptop        | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 2       | Chair         | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "| 3       | Laptop        | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 4       | Chair         | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "| 5       | Laptop        | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 6       | Chair         | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "| 7       | Laptop        | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 8       | Chair         | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "| 9       | Unknown Item  | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 10      | Unknown Item  | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "| 11      | Laptop        | Technology | A-1              | B-5                  | 100      | High     | 50                       |\n",
       "| 12      | Chair         | Other      | B-2              | B-5                  | 200      | Medium   | 100                      |\n",
       "\n",
       "---\n",
       "\n",
       "## Detailed Storage Optimization Recommendations\n",
       "\n",
       "Based on the data and model insights, here are the detailed recommendations:\n",
       "\n",
       "### A. Immediate Action: Full Consolidation to B-5\n",
       "\n",
       "1.  **Execute the Relocation Plan:** Systematically move all inventory from A-1 and B-2 to B-5 as per the \"List of Items Flagged for Relocation\" above.\n",
       "    *   **Prioritization:** Consider prioritizing the relocation of 'High' priority items (Laptops, Items 1,3,5,7,9,11) first, as their accessibility is critical. However, given the universal recommendation, moving items by current location (e.g., clear A-1 then B-2) might be logistically simpler if B-5 has general purpose slots.\n",
       "    *   **Batching:** Group similar items or items from the same current location for efficient movement.\n",
       "    *   **Minimize Disruption:** Plan the relocation during off-peak hours or in phases to minimize impact on order fulfillment.\n",
       "\n",
       "2.  **Optimize Slotting within B-5:** Once items arrive at B-5, don't just put them anywhere. Apply best practices:\n",
       "    *   **Velocity-Based Slotting:** Since both Laptops and Chairs are relatively fast-moving, place them in the most accessible and frequently picked areas within B-5.\n",
       "    *   **Size/Weight Considerations:** Place heavier/bulkier items (Chairs) on lower shelves for ergonomic picking and safety. Laptops can occupy mid-level shelves.\n",
       "    *   **Category Grouping:** If B-5 is large enough, consider grouping items by category ('Technology', 'Other') to streamline future picking paths for multi-item orders.\n",
       "    *   **High-Priority Zones:** If B-5 has designated \"hot zones\" or automated retrieval, ensure 'High' priority items (Laptops) are placed there.\n",
       "\n",
       "### B. Strategic Re-evaluation of Locations A-1 and B-2\n",
       "\n",
       "1.  **Evaluate for Decommissioning/Re-purposing:** With all inventory moved out, A-1 and B-2 will become empty.\n",
       "    *   **Capacity Needs:** Determine if you anticipate future inventory growth that would necessitate reactivating these locations.\n",
       "    *   **Alternative Uses:** Could A-1 and B-2 be re-purposed for:\n",
       "        *   Returns processing areas?\n",
       "        *   Kitting or assembly zones?\n",
       "        *   Temporary overflow for peak seasons?\n",
       "        *   Staging areas for outbound shipments?\n",
       "        *   Equipment storage?\n",
       "    *   **Cost Analysis:** If no immediate re-purpose is identified, consider the cost savings of closing or reducing operations in these areas (e.g., lighting, HVAC, maintenance).\n",
       "\n",
       "2.  **Infrastructure Assessment:** While empty, this is an ideal time to conduct maintenance, upgrades, or safety checks on the shelving, flooring, and other infrastructure in A-1 and B-2.\n",
       "\n",
       "### C. Continuous Improvement & Data Management\n",
       "\n",
       "1.  **Understand the Model's Logic:** Gain deeper insights into *why* the model consistently recommends B-5. What criteria (e.g., item velocity, size, weight, priority, cost of access, available capacity) does it prioritize? This understanding is crucial for:\n",
       "    *   **Future Slotting:** Applying the same logic for new incoming inventory.\n",
       "    *   **Warehouse Design:** Informing future expansions or redesigns of other locations.\n",
       "    *   **Model Validation:** Ensuring the model's recommendations align with operational realities and deliver desired efficiency gains.\n",
       "\n",
       "2.  **Improve Data Quality:**\n",
       "    *   **Resolve Missing Item Names:** Investigate and update the `ItemName` for `ItemId` 9 and 10 to ensure complete and accurate inventory records.\n",
       "    *   **Standardize Data Entry:** Implement procedures to prevent future occurrences of missing or inconsistent data points.\n",
       "\n",
       "3.  **Monitor Performance Post-Relocation:**\n",
       "    *   **Key Performance Indicators (KPIs):** Track metrics such as:\n",
       "        *   **Picking Efficiency:** Time taken per pick, picks per hour.\n",
       "        *   **Order Fulfillment Cycle Time:** From order placement to dispatch.\n",
       "        *   **Space Utilization in B-5:** Ensure the new location isn't becoming over-densified.\n",
       "        *   **Labor Costs:** Reductions in travel time within the warehouse.\n",
       "        *   **Inventory Accuracy:** Maintain high levels of accuracy in B-5.\n",
       "    *   **Feedback Loop:** Use these KPIs to validate the success of the optimization and provide feedback to further refine the model or operational processes.\n",
       "\n",
       "4.  **Consider Item Lifecycle Management:**\n",
       "    *   While all items currently have `Dispose: False`, establish clear criteria and processes for identifying and managing slow-moving, obsolete, or damaged inventory in the future. This prevents dead stock from occupying valuable space.\n",
       "\n",
       "---\n",
       "\n",
       "By implementing these recommendations, you can significantly enhance your storage efficiency, streamline operations, and potentially reduce operational costs by leveraging the optimized capabilities of location B-5."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "location_predictions = []\n",
    "for item in inventoryData:\n",
    "    location_predictions.append({\n",
    "        'Item Id': item['ItemId'],\n",
    "        'Current Location': item['Location'],\n",
    "        'Predicted Location': s.predict_location({\n",
    "            'Priority': item['Priority'],\n",
    "            'Product_Type': item['Category'],\n",
    "            'Size': item['Size'],\n",
    "            'Order_Quantity': item['Quantity'],\n",
    "            'Weight': item['Weight']\n",
    "        })[0]\n",
    "    })\n",
    "\n",
    "section_storage_optimizations = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Provide detailed storage optimization recommendations based on:\n",
    "\n",
    "1. Current storage utilization metrics\n",
    "2. Model-predicted optimal locations vs current locations\n",
    "3. List of items flagged for relocation, including:\n",
    "   - Current location\n",
    "   - Recommended location\n",
    "\n",
    "Data:\n",
    "{inventoryData}\n",
    "{location_predictions}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(section_storage_optimizations.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Storage Anomalies Detected\n",
       "\n",
       "The following anomalies have been identified in the storage table:\n",
       "\n",
       "### 1. Location Mismatches\n",
       "These items are not in their predicted storage locations, indicating a potential misplacement or pending relocation.\n",
       "\n",
       "*   **Item ID:** 1\n",
       "    **Name:** Laptop\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 2\n",
       "    **Name:** Chair\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 3\n",
       "    **Name:** Laptop\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 4\n",
       "    **Name:** Chair\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 5\n",
       "    **Name:** Laptop\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 6\n",
       "    **Name:** Chair\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 7\n",
       "    **Name:** Laptop\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 8\n",
       "    **Name:** Chair\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 9\n",
       "    **Name:** [N/A]\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 10\n",
       "    **Name:** [N/A]\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 11\n",
       "    **Name:** Laptop\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "*   **Item ID:** 12\n",
       "    **Name:** Chair\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's current location does not match its predicted storage location.\n",
       "\n",
       "### 2. Missing Item Information\n",
       "These items are missing crucial identification details.\n",
       "\n",
       "*   **Item ID:** 9\n",
       "    **Name:** [N/A]\n",
       "    **Current Location:** A-1\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's name is missing, making identification difficult.\n",
       "\n",
       "*   **Item ID:** 10\n",
       "    **Name:** [N/A]\n",
       "    **Current Location:** B-2\n",
       "    **Predicted Location:** B-5\n",
       "    **Reason:** The item's name is missing, making identification difficult."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "section_anomalies_detected = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "f'''Generate an anomalies section that lists all detected storage anomalies detected in a table. Include each item's current location, predicted location, item id, and name.\n",
    "Include the reason for each anomaly.\n",
    "\n",
    "Data:\n",
    "{s.detect_anomalies(inventoryData)}\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(section_anomalies_detected.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown_pdf import MarkdownPdf, Section\n",
    "\n",
    "# Read Markdown content\n",
    "mdc = f'''<h1 style=\"text-align:center;\">Monthly Report</h1><br>\n",
    "\n",
    "# Products Overview:\n",
    "section_products_overview.text\n",
    "\n",
    "# Category Distribution:\n",
    "section_category_distribution.text\n",
    "\n",
    "# Product Usage Forecast:\n",
    "section_product_usage.text\n",
    "\n",
    "# Sales Insights:\n",
    "{section_sales_insights.text}\n",
    "\n",
    "# Storage Optimizations:\n",
    "{section_storage_optimizations.text}\n",
    "\n",
    "# Anomalies Detected:\n",
    "{section_anomalies_detected.text}\n",
    "\n",
    "# Summary:\n",
    "section_summary.text\n",
    "'''\n",
    "pdf = MarkdownPdf()\n",
    "pdf.add_section(Section(mdc)) # Add Section(md_content, user_css=css_content) for custom CSS\n",
    "pdf.save(\"MonthlyReport.pdf\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompting.ipynb",
   "toc_visible": true
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:it3100] *",
   "language": "python",
   "name": "conda-env-it3100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
