{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2025 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeadDkMiISin"
   },
   "source": [
    "# Gemini API: Prompting Quickstart\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpOYALec6N8Z"
   },
   "source": [
    "This notebook contains examples of how to write and run your first prompts with the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0c13de5f68f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-genai>=1.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4YDYyfRYN7L"
   },
   "source": [
    "### Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8K1RpmMfh20"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "GOOGLE_API_KEY = input(\"Enter your API key here:\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwtL8wmX4rqP"
   },
   "source": [
    "## Select your model\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](./Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ll79uwEK4uPJ"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\",\"gemini-2.5-flash\",\"gemini-2.5-pro\",\"gemini-2.0-flash\"] {\"allow-input\":true, isTemplate: true}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTNQymX8YN9c"
   },
   "source": [
    "## Run your first prompt\n",
    "\n",
    "Use the `generate_content` method to generate responses to your prompts. You can pass text directly to generate_content, and use the `.text` property to get the text content of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSuyaGmcf6sr"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Give me python code to sort a list\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Database.db import SessionLocal\n",
    "from Database_Table import Inventory, Order\n",
    "\n",
    "def getDbContent():\n",
    "    session = SessionLocal()\n",
    "    inventory_records = session.query(Inventory).all()\n",
    "    order_records = session.query(Order).all()\n",
    "    session.close()\n",
    "    return inventory_records, order_records\n",
    "\n",
    "inventory, order = getDbContent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbtoList(records):\n",
    "    output_list = []\n",
    "    for r in records:\n",
    "        if isinstance(r, Inventory):\n",
    "            data = {\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"Date\": r.Date, \n",
    "                \"Quantity\": r.ItemQuantity, \n",
    "                \"Category\": r.ItemCategory, \n",
    "                \"UnitsSold\": r.UnitsSold, \n",
    "                \"Weight\": r.Weight, \n",
    "                \"Size\": r.Size, \n",
    "                \"Priority\": r.Priority, \n",
    "                \"Dispose\": r.Dispose\n",
    "            }\n",
    "        elif isinstance(r, Order):\n",
    "            data = {\n",
    "                \"OrderId\": r.OrderId,\n",
    "                \"ItemId\": r.ItemId, \n",
    "                \"OrderQuantity\": r.OrderQuantity, \n",
    "                \"Sales\": r.Sales, \n",
    "                \"Price\": r.Price, \n",
    "                \"Discount\": r.Discount,\n",
    "                \"Profit\": r.Profit, \n",
    "                \"DateOrdered\": r.DateOrdered,\n",
    "                \"DateReceived\": r.DateReceived,\n",
    "                \"CustomerSegment\": r.CustomerSegment\n",
    "            }\n",
    "        else:\n",
    "            continue\n",
    "        output_list.append(data)\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "inventoryData = dbtoList(inventory)\n",
    "orderData = dbtoList(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A-5']\n",
      "['Accessories', 'As Seen on  TV!', 'Baby ', 'Baseball & Softball', 'Basketball', 'Books ', 'Boxing & MMA', 'CDs ', 'Cameras ', 'Camping & Hiking', 'Cardio Equipment', \"Children's Clothing\", 'Cleats', 'Computers', 'Consumer Electronics', 'Crafts', 'DVDs', 'Electronics', 'Fishing', 'Fitness Accessories', 'Garden', \"Girls' Apparel\", 'Golf Apparel', 'Golf Bags & Carts', 'Golf Balls', 'Golf Gloves', 'Golf Shoes', 'Health and Beauty', 'Hockey', 'Hunting & Shooting', 'Indoor/Outdoor Games', \"Kids' Golf Clubs\", 'Lacrosse', \"Men's Clothing\", \"Men's Footwear\", \"Men's Golf Clubs\", 'Music', 'Pet Supplies', 'Shop By Sport', 'Soccer', 'Sporting Goods', 'Strength Training', 'Tennis & Racquet', 'Toys', 'Trade-In', 'Video Games', 'Water Sports', \"Women's Apparel\", \"Women's Clothing\", \"Women's Golf Clubs\"]\n",
      "(25.296114, 'Accessories')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:05:34] WARNING: C:\\b\\abs_52v3kadn8m\\croot\\xgboost-split_1748343554494\\work\\src\\gbm\\../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "D:\\Yong Meng Lee\\anaconda3\\envs\\it3100\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "class Supervised_Models:\n",
    "    # Location Prediction Model\n",
    "    def predict_location(input_data):\n",
    "        with open('../../Supervised models/Samuel/storage_prediction_model.pkl', 'rb') as file:\n",
    "            storage_prediction_model = pickle.load(file)\n",
    "            \n",
    "        categorical_features = {\n",
    "            'Priority': ['High','Low','Medium'],\n",
    "            'Product_Type': ['Clothing','Electronics','Home Goods','Sports'],\n",
    "            'Size': ['Large','Medium','Small']\n",
    "        }\n",
    "        numerical_features = ['Order_Quantity', 'Weight']\n",
    "        one_hot_columns = []\n",
    "        \n",
    "        for feature, values in categorical_features.items():\n",
    "            for value in values:\n",
    "                one_hot_columns.append(f\"{feature}_{value}\")\n",
    "            \n",
    "        # Combine with numerical features to get all feature names\n",
    "        all_feature_names = one_hot_columns + numerical_features\n",
    "\n",
    "        features_dict = {col: 0 for col in all_feature_names}\n",
    "    \n",
    "        # Set one-hot encoded features\n",
    "        for feature, values in categorical_features.items():\n",
    "            if feature in input_data:\n",
    "                selected_value = input_data[feature]\n",
    "                one_hot_col = f\"{feature}_{selected_value}\"\n",
    "                if one_hot_col in features_dict:\n",
    "                    features_dict[one_hot_col] = 1\n",
    "    \n",
    "        # Set numerical features\n",
    "        for feature in numerical_features:\n",
    "            if feature in input_data:\n",
    "                features_dict[feature] = float(input_data[feature])\n",
    "        \n",
    "        # Convert to array in the correct order\n",
    "        features_array = np.array([features_dict[col] for col in all_feature_names]).reshape(1, -1)\n",
    "\n",
    "        prediction = storage_prediction_model.predict(features_array)\n",
    "        return prediction\n",
    "\n",
    "    \n",
    "    # Demand forecast model\n",
    "    def predict_demand_forecast(input_data):\n",
    "        demand_forecast_model = joblib.load('../../Supervised models/ShernFai/model/salesforecast_model.pkl')\n",
    "        with open('../../Supervised models/ShernFai/model/salesforecast_preprocessor.pkl', 'rb') as f:\n",
    "            preprocessor_data = pickle.load(f)\n",
    "\n",
    "        # Extract preprocessor components\n",
    "        le_category = preprocessor_data['label_encoder_category']\n",
    "        reference_date = preprocessor_data['reference_date']\n",
    "        unique_categories = preprocessor_data['unique_categories']\n",
    "        feature_columns = preprocessor_data['feature_columns']\n",
    "\n",
    "        print(unique_categories)\n",
    "\n",
    "        # Get data\n",
    "        category_name = input_data['category']\n",
    "        future_month = input_data['month']\n",
    "        product_category_id = int(input_data['product_category_id'])\n",
    "        avg_price = float(input_data['avg_price'])\n",
    "        customer_segment = input_data['customer_segment']\n",
    "        discount_rate = float(input_data['discount_rate'])\n",
    "        \n",
    "        # Parse the future date\n",
    "        future_date = pd.to_datetime(future_month)\n",
    "        \n",
    "        # Calculate time features for the future date\n",
    "        months_since_start = ((future_date - reference_date).days / 30.44)\n",
    "        \n",
    "        # Create test data with numerical time features\n",
    "        test_data = {\n",
    "            'Category Name': category_name,\n",
    "            'Product Category Id': product_category_id,\n",
    "            'Average Product Price': avg_price,\n",
    "            'Customer Segment': customer_segment,\n",
    "            'Order Item Discount Rate': discount_rate,\n",
    "            # Time features (numerical - can handle ANY future date!)\n",
    "            'Year': future_date.year,\n",
    "            'Month': future_date.month,\n",
    "            'Quarter': future_date.quarter,\n",
    "            'Months_Since_Start': int(months_since_start),\n",
    "            'Month_Sin': np.sin(2 * np.pi * future_date.month / 12),\n",
    "            'Month_Cos': np.cos(2 * np.pi * future_date.month / 12),\n",
    "            'Year_Trend': future_date.year - reference_date.year\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        test_df = pd.DataFrame([test_data])\n",
    "        \n",
    "        # Handle unknown category\n",
    "        if category_name not in le_category.classes_:\n",
    "            print(f\"Unknown category '{category_name}' - using default: {le_category.classes_[0]}\")\n",
    "            test_df['Category Name'] = le_category.classes_[0]\n",
    "            category_name = le_category.classes_[0]\n",
    "        \n",
    "        # Encode category\n",
    "        test_df['Category Name'] = le_category.transform(test_df['Category Name'])\n",
    "        \n",
    "        # One-hot encode customer segment\n",
    "        test_df = pd.get_dummies(test_df, columns=['Customer Segment'], drop_first=True)\n",
    "        \n",
    "        # Ensure same columns as training (crucial!)\n",
    "        test_df = test_df.reindex(columns=feature_columns, fill_value=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = demand_forecast_model.predict(test_df)[0]\n",
    "        \n",
    "        return prediction, category_name\n",
    "        \n",
    "\n",
    "\n",
    "# Testing\n",
    "print(Supervised_Models.predict_location({\n",
    "    \"Priority\": \"High\",\n",
    "    \"Product_Type\": \"Sports\",\n",
    "    \"Size\": \"Small\",\n",
    "    \"Order_Quantity\": 9,\n",
    "    \"Weight\": 9.78\n",
    "}))\n",
    "\n",
    "print(Supervised_Models.predict_demand_forecast({\n",
    "    'category': \"Accessories\",\n",
    "    'month': 5,\n",
    "    'product_category_id': 2,\n",
    "    'avg_price': 10.0,\n",
    "    'customer_segment': \"Consumer\",\n",
    "    'discount_rate': 0.12\n",
    "}))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Products Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Product Usage Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_insights = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "'''Generate a sales insights report that describes information for the following areas:\n",
    "\n",
    "1. Sales Trends: Summarize sales over the past month, quarter, and year. Provide insights on which product categories are seeing the highest demand.\n",
    "2. Product Performance: Analyze the best-selling products by quantity and revenue. Highlight the top 3 performing products.\n",
    "3. Product Demand Forecast: Based on the historical sales and usage probability, forecast the demand for the next period.\n",
    "4. Restocking or Discontinuation: Recommend which products should be restocked and which should be discontinued, based on sales trends and inventory levels.\n",
    "\n",
    "Data:\n",
    "- Historical sales data: {sales_data}\n",
    "- Sales volume predictions: {sales_predictions}\n",
    "- Product categories: {product_categories}\n",
    "- Current inventory levels: {current_inventory}\n",
    "- Usage probabilities: {usage_probabilities}\n",
    "- Product classifications: {product_classifications}'''\n",
    ")\n",
    "\n",
    "display(Markdown(sales_insights.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_optimizations = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "'''Provide detailed storage optimization recommendations based on:\n",
    "\n",
    "1. Current storage utilization metrics\n",
    "2. Model-predicted optimal locations vs current locations\n",
    "3. List of items flagged for relocation, including:\n",
    "   - Current location\n",
    "   - Recommended location\n",
    "   - Reason for recommendation\n",
    "4. Estimated space savings from optimizations\n",
    "\n",
    "Data:\n",
    "{current_storage_data}\n",
    "{location_predictions}\n",
    "{anomaly_flags}'''\n",
    ")\n",
    "\n",
    "display(Markdown(storage_optimizations.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_detected = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\n",
    "'''Generate an anomalies section that:\n",
    "\n",
    "1. Lists all detected anomalies categorized by:\n",
    "   - Misplaced items\n",
    "   - Severity\n",
    "   - Data inconsistencies\n",
    "2. For each anomaly, provide:\n",
    "   - Item details\n",
    "   - Nature of anomaly\n",
    "   - Recommended corrective action\n",
    "   - Priority level (high/medium/low)\n",
    "3. Summary of potential impact if not addressed.\n",
    "\n",
    "Data:\n",
    "'''\n",
    ")\n",
    "\n",
    "display(Markdown(anomalies_detected.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65476e75ece0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56f68c900144"
   },
   "source": [
    "Every prompt you send to the model includes parameters that control how the model generates responses. Use a `types.GenerateContentConfig` to set these, or omit it to use the defaults.\n",
    "\n",
    "Temperature controls the degree of randomness in token selection. Use higher values for more creative responses, and lower values for more deterministic responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3c68071ed8b"
   },
   "source": [
    "Note: Although you can set the `candidate_count` in the generation_config, 2.0 and later models will only return a single candidate at the this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c97c16e6a961"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some cat facts for you:\n",
       "\n",
       "1.  Domestic cats spend about **70% of their day sleeping** and 15% grooming.\n",
       "2.  The average lifespan of an outdoor cat is significantly shorter (2-5 years) compared to an **indoor cat (10-15+ years)**.\n",
       "3.  Cats use their **whiskers** to \"feel\" the world around them, gauge openings, and detect changes in air currents. They are highly sensitive tactile organs.\n",
       "4.  A group of cats is called a **clowder**, a group of kittens is called a kindle.\n",
       "5.  Cats have a unique scent gland on their paws, which is why they **knead** â€” it's a way of marking territory and showing contentment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents='Give me a numbered list of cat facts.',\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=2000,\n",
    "        temperature=1.9,\n",
    "        stop_sequences=['\\n6'] # Limit to 5 facts.\n",
    "    )\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvkDhXtHgol7"
   },
   "source": [
    "## Learn more\n",
    "\n",
    "There's lots more to learn!\n",
    "\n",
    "* For more fun prompts, check out [Market a Jetpack](https://github.com/google-gemini/cookbook/blob/main/examples/Market_a_Jet_Backpack.ipynb).\n",
    "* Check out the [safety quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb) next to learn about the Gemini API's configurable safety settings, and what to do if your prompt is blocked.\n",
    "* For lots more details on using the Python SDK, check out the [get started notebook](./Get_started.ipynb) or the [documentation's quickstart](https://ai.google.dev/tutorials/python_quickstart)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Prompting.ipynb",
   "toc_visible": true
  },
  "google": {
   "image_path": "/static/site-assets/images/docs/logo-python.svg",
   "keywords": [
    "examples",
    "gemini",
    "beginner",
    "googleai",
    "quickstart",
    "python",
    "text",
    "chat",
    "vision",
    "embed"
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:it3100] *",
   "language": "python",
   "name": "conda-env-it3100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
